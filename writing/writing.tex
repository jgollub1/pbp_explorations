\documentclass[chapterprefix=false]{report}
\setlength{\oddsidemargin}{0 in}
\setlength{\evensidemargin}{0 in}
\setlength{\topmargin}{0 in}
\setlength{\textwidth}{5.7 in}
\setlength{\textheight}{8.0 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0.3 in}
\setlength{\parskip}{0.1 in}

\usepackage{titlesec}

\titleformat{\chapter}{\huge}{\thechapter.}{20pt}{\huge}

\usepackage{epsf}
\usepackage{pseudocode}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{textcomp}
\usepackage{tikz}
\usepackage{csquotes}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{seqsplit}
\graphicspath{{photos/}}

\usepackage{url}
\usepackage{cite}
\usepackage[parfill]{parskip}
%\usepackage{natbib}
%\bibliographystyle{unsrtnat}

\usetikzlibrary{arrows}
\tikzset{
    vertex/.style={circle,draw,minimum size=1.5em},
    edge/.style={->,> = latex'}
}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

% \usepackage{times}
% \usepackage{mathptm}

\def\O{\mathop{\smash{O}}\nolimits}
\def\o{\mathop{\smash{o}}\nolimits}
\newcommand{\e}{{\rm e}}
\newcommand{\R}{{\bf R}}
\newcommand{\Z}{{\bf Z}}
\newcommand{\h}{1.2}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
 
\begin{document}
 
\tableofcontents{}
 
\chapter{Introduction}
 
\section{In-game Sports Analytics}

$\newline$
``The win probability graphic/discussion on ESPN is literally taking a sword and sticking it through the chest of any fun left in baseball''
\\[5pt]
\centerline{{ --- Kenny Ducey (@KennyDucey) April 2, 2017}}

$\newline$
``ESPN showing win probability is extremely good. Next up, run expectancy!''
\\[5pt]
\centerline{{\rm --- Neil Weinberg (@NeilWeinberg44) April 4, 2017}}

``Thank the Lord we have the ESPN Win Probability stat to tell us the team that's ahead has a good chance to win.''
\\[5pt]
\centerline{{\rm --- Christian Schneider (@Schneider\_CM) April 17, 2017}}

In recent years, win probability has become increasingly prevalent in sports broadcasting. Brian Burke, an NFL commentator, has posted live win-probability graphs of NFL playoff games on his website for the past few years \footnote{http://www.advancedfootballanalytics.com/index.php/home/tools/live-playoff-probabilities}. Earlier this year, ESPN began to post win probabilities atop the score box in televised Major League Baseball games. Despite mixed reactions from fans, as shown above, these developments represent a transition in sports broadcasting's modern narrative. 

%..Make an argument for the value of in-match forecasting, despite angry reactions..

A win probability from any score line communicates how much a team or player is favored to win. While one can produce this from any model of choice, those in sports analytics strive to produce the most well-informed estimate available.  With the recent proliferation of online betting, in-match win probability dictates an entire market of its own. Betfair's platform  matched over 40 million Euros during the 2011 French Open Final \cite{Huang2011}; other high-profile matches often draw comparable volume over betting exchanges. While the majority of tennis prediction papers concern pre-match prediction, around 80$\%$ of online betting occurs while matches are in progress \cite{Sipko2015}. At the very least, in-match win probability concerns all participants in this betting market, if not the general public.

%While one can produce this from any model of choice, sports analytics strives to produce the most well-informed estimate available. 
%While tennis has yet to broadcast win probabilities, 

%demonstrates an individual model’s most informed guess at how likely a player is to win the match

%Drawing upon past research and exploring new methods, this paper searches for the most effective approach to in-match forecasting.

\section{History of Tennis Forecasting}
Plenty of research on tennis match prediction exists over the past twenty years. Klaassen and Magnus tested the assumption that points in a tennis match are independent and identically distributed \cite{KlaassenandMagnus2001}. Under this assumption, they construct a hierarchical Markov model in conjunction with tennis' scoring system. From this model, they offer an analytical equation for match-win probability from any score, given each individual player's probability of winning a point on serve \cite{Klaassen2003}.  Barnett and Clarke then offer a method of estimating each player's serve probability from historical data \cite{BarnettandClarke2005}. Years later, Bevc proposed updating each these serve probabilities with a beta distribution between each point and computing the corresponding win probability with the above model \cite{Bevc2015}. Recently, Kovalchik assessed performance of 11 different pre-match prediction models on all ATP tour-level matches in 2014 \cite{Kovalchik2016}.

Over the past several years, Jeff Sackmann (offer footnote to website) has released the largest publicly available library of tennis datasets via github. This collection contains match summaries of every ATP and WTA match in the Open Era, point-by-point summaries of nearly 100,000 tour-level and satellite matches, and a crowd-sourced match-charting project spanning over 3000 matches, where volunteers record each shot’s type and direction over an entire match. While 538 and Kovalchik use Jeff Sackmann’s match data to generate elo ratings, none of the aforementioned papers have tested models with his point-by-point dataset.

As past papers have spanned several decades, datasets and model evaluation are not consistent. Klaassen and Magnus' original point-based model and Bevc's beta experiments both apply methods to around 500 Wimbledon matches from 1991-94. Barnett explores point-based models in great depth, yet primarily applies them to a single marathon match between Andy Roddick and Younes El Aynaoui from the 2002 Australian Open \cite{Barnett2006}. Except for Bevc, none of these papers attempt to obtain an overall assessment of in-game match prediction with metrics such as accuracy or cross-entropy. While Bevc does record accuracy of results over 500 Wimbledon matches, he only reports accuracy of predictions in the third set and onwards, a subset of the entire dataset. In other words, no one has taken all in-game prediction models and tested them at a large scale. For this reason, I will test all relevant in-match prediction methods on thousands of matches within the past seven years.

%However, Jeff Sackmann has recently released the largest publicly available tennis dataset via github. This collection contains match summaries of every ATP and WTA match in the Open Era, point-by-point summaries of nearly 100,000 matches—both tour-level and satellite--and a crowd-sourced match-charting project spanning 2800 matches, where volunteers record each shot’s type and direction in every point. While 538 and Kovalchik use Jeff Sackmann’s match data to refine their own elo system for pre-match prediction, no papers on in-match prediction have used his point-by-point dataset. With over 10,000 ATP and WTA tour-level matches from 2010-2017, I compare existing approaches side-by-side and explore new methods to in-match prediction.  Just as Kovalchik does with pre-match prediction models, I attempt to find the GOAT (greatest of all-time) of in-match prediction models.

This paper combines elo ratings, a wealth of data, and current technology to provide a similar survey of which in-match prediction methods perform the best. I build upon past research by testing variations of previous state-of-the-art methods, and applying new concepts to these datasets, from probability models used in football to elo-induced serving percentages.

%(Can reference older sports forecasting mentioned in Nettleton and Lock...)

 
\section{Match/Point-by-Point Datasets}
 
 This project uses two different types of datasets: one with match summary statistics and one with point-by-point information. Both are publicly available on github, courtesy of Jeff Sackmann (\url{https://github.com/JeffSackmann}). We primarily use the matches dataset under ``\texttt{tennis\_atp}'' to test pre-match prediction methods. This dataset covers over 150,000 tour-level matches, dating back to 1968. Features include player qualities, such as nationality or dominant hand, as well as match statistics, like serve/return points won.
 
 
 The data in ``\texttt{tennis\_pointbypoint}'' offers more granular detail about a single match's point progression. Each match contains a string listing the order in which players won points and switched serve. As the ATP does not publicly list point-by-point summaries, this information was presumably extracted from a betting website.

\section{Implementation}

With the above datasets serving as a basis for this project, thorough re-formatting of the data was required in order to connect point-by-point strings to their corresponding rows in the match dataset.

As both datasets included player names, year, and score, we connected matches across datasets with a hashing scheme \footnote{eg. hash(matchX) = ``Roger Federer Tomas Berdych 2012 3-6 7-5 7-5''}. Due to observed inconsistencies, we canonicalized player names between match and point-by-point datasets $\footnote{eg. ``Stan Wawrinka'' $\rightarrow$ ``Stanislas Wawrinka'', ``Federico Del Bonis'' $\rightarrow$ ``Federico Delbonis''}$ in order to maximize the number of available matches with point-by-point summaries. While a portion of the point-by-point summaries are from satellite events, we were able to match around 10,600/12,000 point-by-point strings to their respective tour-level matches. Then, we could associate information generated from the match dataset's entirety (elo ratings, year-long adjusted serve stats, etc) with these point-by-point strings.

To view this process in more depth or access any of the resulting datasets, visit \url{https://github.com/jgollub1/tennis_match_prediction}. Implementations of each method in this project, and instructions on how to generate all relevant statistics, are also provided.


\chapter{Scoring}
Tennis' scoring system consists of three levels: sets, games, and points. Consider a tennis match between two entities, $p_i$ and $p_j$. We can represent any score as $(s_i,s_j,g_i,g_j,{x}_i,{x}_j)$ where $i$ is serving and $s_k,g_k,x_k$ represent $p_k$'s score in sets, games, and points, respectively. The players alternate serve each game and continue until someone clinches the match by winning two sets (best-of-three) or three sets (best-of-five) $\footnote{The best-of-five format is typically reserved for men's grand slam and Davis Cup events}$.

The majority of in-play tennis models utilize a graphical structure that embodies the levels within tennis' scoring system. Madurska referred to this as a hierarchical Markov Model \cite{Madurska2012}. Barnett formally defines this representation for tennis scores \cite{BarnettandClarke2002}. With $p_i$ and $p_j$ winning points on serve with probabilities $f_{ij},f_{ji}$, each in-match scoreline $(s_i,s_j),(g_i,g_j),({x}_i,{x}_j)$ progresses to one of its two neighbors $(s_i,s_j),(g_i,g_j),({x}_i+1,{x}_j)$ and $(s_i,s_j),(g_i,g_j),({x}_i,{x}_j+1)$ with transition probabilities dependent on the current server. Assuming all points in a match are i.i.d. between servers, we can then use the below model to recursively determine win probability:

\begin{center}
$P_m(s_i,s_j,g_i,g_j,{x}_i,{x}_j)$ = probability that $p_i$ wins the match when serving from this scoreline

$P_m(s_i,s_j,g_i,g_j,{x}_i,{x}_j) = f_{ij}*P_m(s_i,s_j,g_i,g_j,{x}_i+1,{x}_j) + (1-f_{ij}) P_m(s_i,s_j,g_i,g_j,{x}_i,{x}_j+1)$
\end{center}
In the following sections, we specify boundary values to each level of our hierarchical model. 

%With these specifications, we can analytically compute win probability at any point in the match.


\section{Modeling games}

Within a game, either $p_i$ or $p_j$ serves every point. Every game starts at (0,0) and to win a game, a player must win four or more points by a margin of at least two $\footnote{While tennis officially  refers to a game's first three points as 15,30,40 we will call them 1,2,3 for simplicity's sake}$. Consequently, all games with valid scores $(x_i,x_j)$ where $x_i+x_j$ \textgreater $6; |x_i-x_j| \leq 1$ are reduced to (3,3), (3,2), or (2,3). Furthermore, the win probability at (3,3) can be calculated directly. From (3,3), the server wins the next two points with probability $f_{ij}^2$, the returner wins the next two points with probability $(1-f_{ij})^2$, or both players split the two points and return to (3,3) with probability $2f_{ij}(1-f_{ij})$. Relating the game's remainder to a geometric sequence, we find $P_g(3,3) = \frac{f_{ij}^2}{f_{ij}^2+(1-f_{ij})^2}$.

Possible sequences of point scores in a game:

a - player $i$ wins the following point

b - player $j$ wins the following point

\begin{tikzpicture} [scale=1]
\tikzset{VertexStyle/.style = {shape = circle,inner sep=0x}}
\node[vertex] (1) at (0,0) {$0,0$};
\node[vertex] (2) at (2,.8) {$1,0$};
\node[vertex] (3) at (2,-.8) {$0,1$};
\node[vertex] (4) at (4,0) {$1,1$};
\node[vertex] (7) at (4,1.6) {$2,0$};
\node[vertex] (8) at (4,-1.6) {$0,2$};
\node[vertex] (5) at (6,.8) {$2,1$};
\node[vertex] (6) at (6,-.8) {$1,2$};
\node[vertex] (9) at (6,2.4) {$3,0$};
\node[vertex] (10) at (6,-2.4) {$0,3$};
\node[vertex] (11) at (8,1.6) {$3,1$};
\node[vertex] (12) at (8,-1.6) {$1,3$};
\node[vertex] (13) at (8,0) {$2,2$};

\node[vertex] (14) at (12,3.2) {$G_1$};
\node[vertex] (15) at (12,-3.2) {$G_1^{c}$};
\node[vertex] (16) at (10,.8) {$3,2$};
\node[vertex] (17) at (10,-.8) {$2,3$};
\node[vertex] (18) at (12,0) {$3,3$};

\draw[edge] (1) -- (2) node[midway, above] {$a$};
\draw[edge] (1) -- (3) node[midway, above] {$b$};
\draw[edge] (2) -- (4) node[midway, above] {$b$};
\draw[edge] (3) -- (4) node[midway, above] {$a$};
\draw[edge] (2) -- (7) node[midway, above] {$a$};
\draw[edge] (3) -- (8) node[midway, above] {$b$};
\draw[edge] (4) -- (5) node[midway, above] {$a$};
\draw[edge] (4) -- (6) node[midway, above] {$b$};
\draw[edge] (7) -- (9) node[midway, above] {$a$};
\draw[edge] (7) -- (5) node[midway, above] {$b$};
\draw[edge] (8) -- (6) node[midway, above] {$a$};
\draw[edge] (8) -- (10) node[midway, above] {$b$};
\draw[edge] (9) -- (11) node[midway, above] {$b$};
\draw[edge] (10) -- (12) node[midway, above] {$a$};
\draw[edge] (5) -- (11) node[midway, above] {$a$};
\draw[edge] (6) -- (12) node[midway, above] {$b$};
\draw[edge] (5) -- (13) node[midway, above] {$b$};
\draw[edge] (6) -- (13) node[midway, above] {$a$};
\draw[edge] (13) -- (16) node[midway, above] {$a$};
\draw[edge] (13) -- (17) node[midway, above] {$b$};
\draw[edge] (11) -- (16) node[midway, above] {$b$};
\draw[edge] (12) -- (17) node[midway, above] {$a$};
\draw[edge] (16) -- (18) node[midway, above] {$b$};
\draw[edge] (17) -- (18) node[midway, above] {$a$};
\draw[edge] (9) -- (14) node[midway, above] {$a$};
\draw[edge] (11) -- (14) node[midway, above] {$a$};
\draw[edge] (16) -- (14) node[midway, above] {$a$};
\draw[edge] (10) -- (15) node[midway, above] {$b$};
\draw[edge] (12) -- (15) node[midway, above] {$b$};
\draw[edge] (17) -- (15) node[midway, above] {$b$};
\draw[->, xshift=11.3cm, yshift=1cm] (18) to [bend right=50] (16) node[ sloped,midway,above] {$a$};
\draw[->, xshift=11.3cm, yshift=-1cm] (18) to [bend left=50] (17) node[ sloped,midway,above] {$b$};

\end{tikzpicture}

Boundary values:

\begin{equation}
    P_g(x_i,x_j) 
    \begin{cases}
      1, & \text{if}\ x_1=4,x_2 \leq 2 \\
      0, & \text{if}\ x_2=4,x_1 \leq 2 \\
      \cfrac{f_{ij}^2}{f_{ij}^2+(1-f_{ij})^2}, & \text{if}\ x_1=x_2=3 \\
      f_{ij}*P_g(s_i,s_j,g_i,g_j,{x}_i+1,{x}_j) + (1-f_{ij}) P_g(s_i,s_j,g_i,g_j,{x}_i,{x}_j+1), & \text{otherwise}\ \\
      
    \end{cases}
  \end{equation}

With the above specifications, we can efficiently compute player $i$'s win probability from any score $P_g(x_i,x_j)$.

\section{Modeling sets}

Within a set, $p_i$ or $p_j$ alternate serve every game. Every set starts at (0,0). To win a set, a player must win six or more games by a margin of at least two. If the set score $(6,6)$ is reached, a special tiebreaker game is played to determine the outcome of the match.

Possible sequences of point scores in a game:

$a$ - player 1 wins the following game

$b$ - player 2 wins the following game

$a'$ - player 1 wins the tiebreaker game

$b'$ - player 2 wins the tiebreaker game

\begin{tikzpicture} [scale=.7]
\tikzset{VertexStyle/.style = {shape = circle,inner sep=0x}}
\node[vertex] (1) at (0,0) {$0,0$};
\node[vertex] (2) at (2,\h) {$1,0$};
\node[vertex] (3) at (2,-\h) {$0,1$};
\node[vertex] (4) at (4,2*\h) {$2,0$};
\node[vertex] (5) at (4,0) {$1,1$};
\node[vertex] (6) at (4,-2*\h) {$0,2$};
\node[vertex] (7) at (6,3*\h) {$3,0$};
\node[vertex] (8) at (6,\h) {$2,1$};
\node[vertex] (9) at (6,-\h) {$1,2$};
\node[vertex] (10) at (6,-3*\h) {$0,3$};
\node[vertex] (11) at (8,4*\h) {$4,0$};
\node[vertex] (12) at (8,2*\h) {$3,1$};
\node[vertex] (13) at (8,0) {$2,2$};
\node[vertex] (14) at (8,-2*\h) {$1,3$};
\node[vertex] (15) at (8,-4*\h) {$0,4$};
\node[vertex] (16) at (10,5*\h) {$5,0$};
\node[vertex] (17) at (10,3*\h) {$4,1$};
\node[vertex] (18) at (10,\h) {$3,2$};
\node[vertex] (19) at (10,-\h) {$2,3$};
\node[vertex] (20) at (10,-3*\h) {$1,4$};
\node[vertex] (21) at (10,-5*\h) {$0,5$};
\node[vertex] (22) at (18,6*\h) {$S_1$};
\node[vertex] (23) at (12,4*\h) {$5,1$};
\node[vertex] (24) at (12,2*\h) {$4,2$};
\node[vertex] (25) at (12,0) {$3,3$};
\node[vertex] (26) at (12,-2*\h) {$2,4$};
\node[vertex] (27) at (12,-4*\h) {$1,5$};
\node[vertex] (28) at (18,-6*\h) {$S_1^c$};
\node[vertex] (29) at (14,3*\h) {$5,2$};
\node[vertex] (30) at (14,\h) {$4,3$};
\node[vertex] (31) at (14,-\h) {$3,4$};
\node[vertex] (32) at (14,-3*\h) {$2,5$};
\node[vertex] (33) at (16,2*\h) {$5,3$};
\node[vertex] (34) at (16,0) {$4,4$};
\node[vertex] (35) at (16,-2*\h) {$3,5$};
\node[vertex] (36) at (18,\h) {$5,4$};
\node[vertex] (37) at (18,-\h) {$4,5$};
\node[vertex] (38) at (20,0) {$5,5$};
\node[vertex] (39) at (22,\h) {$6,5$};
\node[vertex] (40) at (22,-\h) {$5,6$};
\node[vertex] (41) at (24,0) {$6,6$};



\draw[edge] (1) -- (2) node[midway, above] {$a$};
\draw[edge] (1) -- (3) node[midway, above] {$b$};
\draw[edge] (2) -- (4) node[midway, above] {$b$};
\draw[edge] (2) -- (5) node[midway, above] {$a$};
\draw[edge] (3) -- (5) node[midway, above] {$a$};
\draw[edge] (3) -- (6) node[midway, above] {$b$};
\draw[edge] (4) -- (7) node[midway, above] {$a$};
\draw[edge] (4) -- (8) node[midway, above] {$b$};
\draw[edge] (5) -- (8) node[midway, above] {$a$};
\draw[edge] (5) -- (9) node[midway, above] {$b$};
\draw[edge] (6) -- (9) node[midway, above] {$a$};
\draw[edge] (6) -- (10) node[midway, above] {$b$};
\draw[edge] (7) -- (11) node[midway, above] {$a$};
\draw[edge] (7) -- (12) node[midway, above] {$b$};
\draw[edge] (8) -- (12) node[midway, above] {$a$};
\draw[edge] (8) -- (13) node[midway, above] {$b$};
\draw[edge] (9) -- (13) node[midway, above] {$a$};
\draw[edge] (9) -- (14) node[midway, above] {$b$};
\draw[edge] (10) -- (14) node[midway, above] {$a$};
\draw[edge] (10) -- (15) node[midway, above] {$b$};
\draw[edge] (11) -- (16) node[midway, above] {$a$};
\draw[edge] (11) -- (17) node[midway, above] {$b$};
\draw[edge] (12) -- (17) node[midway, above] {$a$};
\draw[edge] (12) -- (18) node[midway, above] {$b$};
\draw[edge] (13) -- (18) node[midway, above] {$a$};
\draw[edge] (13) -- (19) node[midway, above] {$b$};
\draw[edge] (14) -- (19) node[midway, above] {$a$};
\draw[edge] (14) -- (20) node[midway, above] {$b$};
\draw[edge] (15) -- (20) node[midway, above] {$a$};
\draw[edge] (15) -- (21) node[midway, above] {$b$};
\draw[edge] (16) -- (22) node[midway, above] {$a$};
\draw[edge] (16) -- (23) node[midway, above] {$b$};
\draw[edge] (17) -- (23) node[midway, above] {$a$};
\draw[edge] (17) -- (24) node[midway, above] {$b$};
\draw[edge] (18) -- (24) node[midway, above] {$a$};
\draw[edge] (18) -- (25) node[midway, above] {$b$};
\draw[edge] (19) -- (25) node[midway, above] {$a$};
\draw[edge] (19) -- (26) node[midway, above] {$b$};
\draw[edge] (20) -- (26) node[midway, above] {$a$};
\draw[edge] (20) -- (27) node[midway, above] {$b$};
\draw[edge] (21) -- (27) node[midway, above] {$a$};
\draw[edge] (21) -- (28) node[midway, above] {$b$};
\draw[edge] (23) -- (22) node[midway, above] {$a$};
\draw[edge] (23) -- (29) node[midway, above] {$b$};
\draw[edge] (24) -- (29) node[midway, above] {$a$};
\draw[edge] (24) -- (30) node[midway, above] {$b$};
\draw[edge] (25) -- (30) node[midway, above] {$a$};
\draw[edge] (25) -- (31) node[midway, above] {$b$};
\draw[edge] (26) -- (31) node[midway, above] {$a$};
\draw[edge] (26) -- (32) node[midway, above] {$b$};
\draw[edge] (27) -- (32) node[midway, above] {$a$};
\draw[edge] (27) -- (28) node[midway, above] {$b$};
\draw[edge] (29) -- (22) node[midway, above] {$a$};
\draw[edge] (29) -- (33) node[midway, above] {$b$};
\draw[edge] (30) -- (33) node[midway, above] {$a$};
\draw[edge] (30) -- (34) node[midway, above] {$b$};
\draw[edge] (31) -- (34) node[midway, above] {$a$};
\draw[edge] (31) -- (35) node[midway, above] {$b$};
\draw[edge] (32) -- (35) node[midway, above] {$a$};
\draw[edge] (32) -- (28) node[midway, above] {$b$};
\draw[edge] (33) -- (22) node[midway, above] {$a$};
\draw[edge] (33) -- (36) node[midway, above] {$b$};
\draw[edge] (34) -- (36) node[midway, above] {$a$};
\draw[edge] (34) -- (37) node[midway, above] {$b$};
\draw[edge] (35) -- (37) node[midway, above] {$a$};
\draw[edge] (35) -- (28) node[midway, above] {$b$};
\draw[edge] (36) -- (22) node[midway, left] {$a$};
\draw[edge] (36) -- (38) node[midway, above] {$b$};
\draw[edge] (37) -- (38) node[midway, above] {$a$};
\draw[edge] (37) -- (28) node[midway, right] {$b$};
\draw[edge] (38) -- (39) node[midway, above] {$a$};
\draw[edge] (38) -- (40) node[midway, above] {$b$};
\draw[edge] (39) -- (22) node[midway, above] {$a$};
\draw[edge] (39) -- (41) node[midway, above] {$b$};
\draw[edge] (40) -- (41) node[midway, above] {$a$};
\draw[edge] (40) -- (28) node[midway, above] {$b$};

\draw[->, xshift=20cm,yshift=6.35cm] (41) to [bend right=30] (22) node[sloped,midway,above,scale=1.4] {$a'$};
\draw[->, xshift=20cm,yshift=-6.35cm] (41) to [bend left=30] (28) node[sloped,midway,above,scale=1.4] {$b'$};


\end{tikzpicture}

Boundary values:
\begin{equation}
    P_s(g_1,g_2) 
    \begin{cases}
      1, & \text{if}\ g_1 \geq 6,g_1-g_2 \geq 2 \\
      0, & \text{if}\ g_2 \geq 6,g_2-g_1 \geq 2 \\
      P_{tb}(s_1,s_2), & \text{if}\ g_1=g_2=6 \\
      P_g(0,0)(1-P_s(g_2,g_1+1))+(1-P_g(0,0))(1-P_s(g_2+1,g_1)), & \text{otherwise}\ \\
    \end{cases}
  \end{equation}

See appendix for the tiebreak game's corresponding diagram**

\section{Modeling a tie-break game}


\section{Modeling a best-of-three match}


a - player 1 wins the following set

b - player 2 wins the following set

\begin{tikzpicture} [scale=1]
\node[vertex] (1) at (0,0) {$0,0$};
\node[vertex] (2) at (2,1) {$1,0$};
\node[vertex] (3) at (2,-1) {$0,1$};
\node[vertex] (4) at (4,0) {$1,1$};
\node[vertex] (5) at (6,1) {$W_1$};
\node[vertex] (6) at (6,-1) {$W_1^{c}$};

\draw[edge] (1) -- (2) node[midway, above] {$a$};
\draw[edge] (1) -- (3) node[midway, above] {$b$};
\draw[edge] (2) -- (4) node[midway, above] {$b$};
\draw[edge] (3) -- (4) node[midway, above] {$a$};
\draw[edge] (2) -- (5) node[midway, above] {$a$};
\draw[edge] (3) -- (6) node[midway, above] {$b$};
\draw[edge] (4) -- (5) node[midway, above] {$a$};
\draw[edge] (4) -- (6) node[midway, above] {$b$};

\end{tikzpicture}

Boundary values:
\begin{equation}
    P_m(s_1,s_2) 
    \begin{cases}
      1, & \text{if}\ g_1 \geq 2 \\
      0, & \text{if}\ g_2 \geq 2 \\
      P_s(0,0)(P_m(s_1+1,s_2))+(1-P_s(0,0))(P_m(s_1,s_2+1)), & \text{otherwise}\ \\
    \end{cases}
  \end{equation}


\section{Win Probability Equation}
Combining the above equations, we can recursively calculate win probability with player $i$ serving from $(s_i,s_j,g_i,g_j,{x}_i,{x}_j)$ as:

$P_m(s_i,s_j,g_i,g_j,{x}_i,{x}_j) = f_{ij}*P_m(s_i,s_j,g_i,g_j,{x}_i+1,{x}_j) + (1-f_{ij}) P_m(s_i,s_j,g_i,g_j,{x}_i,{x}_j+1) \newline 
= P_g(x_i,x_j)*(1-P_m(s_j,s_i,g_j,g_i+1,0,0)) + (1-P_g(x_i,x_j))*(1-P_m(s_j,s_i,g_j+1,g_i,0,0)) \newline
= 
P_g(x_i,x_j)*(1-(P_s(g_j,g_i+1)*P_m(s_j+1,s_i)+(1-P_s(g_j,g_i+1))*P_m(s_j,s_i+1)) + (1-P_g(x_i,x_j))*(1-(P_s(g_j+1,g_i)*P_m(s_j+1,s_i)+(1-P_s(g_j+1,g_i))*P_m(s_j,s_i+1)) = ...$

Thanks to the boundary values at each level, we can programmatically compute this equation.

\chapter{Pre-game Match Prediction}

\section{Overview}
Before play has started, an in-match prediction model cannot draw on information from the match itself. Then, before a match between $p_i$ and $p_j$ commences, the most well-informed pre-match forecast $\hat{\pi}_{ij}(t)$ should serve as a basis for prediction. Therefore, we first explore pre-match models as a starting point for in-match prediction.

Earlier this year, Kovalchik released a survey of eleven different pre-match prediction models, assessing them side-by-side in accuracy, log-loss, calibration, and discrimination. 538's elo-based model and the Bookmaker Consensus Model performed the best. Elo-based prediction incorporates $p_i$ and $p_j$'s entire match histories, while the BCM model incorporates all information encoded in the betting market. In this section, we explore pre-match prediction methods that do not employ market data.

%However, the paper leaves out a point-based method  devised by Klaassen and Magnus that derives serving probabilities from historical player data (combining player outcomes).

\section{Elo Ratings}
Elo was originally developed as a head-to-head rating system for chess players (1978). Recently, 538's elo variant has gained prominence in the media. For a match at time $t$ between $p_i$ and $p_j$ with elo ratings $E_i(t)$ and $E_j(t)$, $p_i$ is forecasted to win with probability:

\begin{center}
$\hat{\pi}_{ij}(t) = (1 + 10^\frac{E_j(t)-E_i(t)}{400})^{-1}$
\end{center}

$p_i$'s rating for the following match $t+1$ is then updated accordingly:

\begin{center}
$E_i(t+1) = E_i(t) + K_{it}*(W_i(t)-\hat{\pi}_{ij}(t))$
\end{center}

$W_i(t)$ is an indicator for whether $p_i$ won the given match, while $K_{it}$ is the learning rate for $p_i$ at time $t$. According to 538's analysts, elo ratings perform optimally when allowing $K_{it}$ to  decay slowly over time (How We're Predicting). With $m_i(t)$ representing the $p_i$'s career matches played at time $t$ we update our learning rate:

\begin{center}
$K_{it} = \frac{250}{(5+m(t))^{.4}} $
\end{center}

This variant updates a player's elo most quickly when we have no information about a player and makes smaller changes as $m_i(t)$ accumulates. To apply this elo rating method to our dataset, we initalize each player's elo rating at $E_i(0)=1500$ and match history $m_i(0)=0$. Then, we iterate through all tour-level matches from 1968-2017 $\footnote{tennis' Open Era began in 1968, when professionals were allowed to enter grand slam tournaments. Before then, only amateurs played these events}$ in chronological order, storing $E_i(t),E_j(t)$ for each match and updating each player's elo accordingly.

\section{ATP Rank}
While Klaassen incorporated ATP rank into his prediction model \cite{Klaassen2003}, Kovalchik and 538 concur that elo outperforms ranking-based methods. On ATP match data from 2010-present, we found:

\begin{center}
\begin{tabular}{ |c|c| } 
 \hline
 method & accuracy
   \\ 
 \hline
  ATP Rank & 66.5 \%
  \\ 
 \hline
  Standard elo & 69.0 \%
  \\ 
 \hline
\end{tabular}
\end{center}

As the ATP does not provide fans a corresponding win-probability equation to go along with their ranking system, we cannot compare the approaches in terms of log loss or calibration. Still, considering its superior accuracy to ATP rank in recent years, models in this paper use elo ratings to represent a player's ability in place of official tour rank.

\section{Point-based Model}
The hierarchical Markov Model offers an analytical solution to win probability $\hat{\pi}_{ij}(t)$ between players $p_i$ and $p_j$, given serving probabilities $f_{ij}$,$f_{ji}$. This hinges on the Markov assumption that transition probabilities from any state only depend on the current state. In other words, all points are independent and the probability of winning a given point only depends on the current server. While this is counter-intuitive, Klaassen and Magnus demonstrated that deviations from the iid assumption within matches are small enough to reasonably justify point-based models \cite{KlaassenandMagnus2001}. Later on, Barnett and Clarke demonstrated a method to estimate $f_{ij},f_{ji}$, given players' historical serve/return averages \cite{BarnettandClarke2005}.

%This model assumes that all points in a tennis match are independent and identically distributed with respect to each server's ability

%outline a way to estimate each player's serving probability from historical serve and return data. 

\begin{center}
$f_{ij} = f_t + (f_i-f_{av})-(g_j-g_{av})$
%\newline

$f_{ji} = f_t + (f_j-f_{av})-(g_i-g_{av})$
\end{center}

Each player's serve percentage is a function of their own serving ability and their opponent's returning ability. $f_t$ denotes the average serve percentage for the match's given tournament, while $f_i,f_j$ and $g_i,g_j$ represent player $i$ and $j$'s percentage of points won on serve and return, respectively. $f_{av},g_{av}$ are tour-level averages in serve and return percentage. Since all points are won by either server or returner, $f_{av} =1-g_{av}$.

As per Barnett and Clarke's formula, we use the previous year's tournament serving statistics to calculate $f_t$ for a given tournament and year, where $(w,y)$ represents the set of all matches played at tournament $w$ in year $y$.

\begin{center}
$f_t(w,y) = \frac{\sum_{k \in (w,y-1)}{\text{\# of points won on serve in match k}}}{\sum_{k \in (w,y-1)}\text{\# of points played in match k}}$
\end{center}

In their paper, Barnett and Clarke only apply this method to a single match: Roddick vs. El Aynaoui Australian Open 2003. Furthermore, their ability to calculate serve and return percentages is limited by aggregate statistics supplied by atpworldtour.com. That is, they can only use year-to-date serve and return statistics to calculate $f_i,g_i,f_j,g_j$. Since the statistics do not list corresponding sample sizes, they must assume that each best-of-three match lasts 165 points, which adds another layer of uncertainty in estimating players' abilities.

Implementing this method with year-to-date statistics proves troublesome because $f_i,g_i$ decrease in uncertainty as $p_i$ accumulates matches throughout the year. Due to availability of data, match forecasts in September will then be far more reliable than ones made in January. However, with our tour-level match dataset, we can keep a year-long tally of serve/return statistics for each player at any point in time. Where $(p_i,y,m)$ represents the set of $p_i$'s matches in year $y$, month $m$, we obtain the following statistics $\footnote{for the current month m, we only collect month-to-date matches} $:

\begin{center}
$f_i(y,m) = \frac{\sum_{t=1}^{12}\sum_{k \in (i,y-1,m+t)}{\text{\# of points won on serve by i in match k}}}{\sum_{t=1}^{12}\sum_{k \in (i,y-1,m+t)}\text{\# of points played on serve by i in match k}}$
%\newline
$g_i(y,m) = \frac{\sum_{t=1}^{12}\sum_{k \in (i,y-1,m+t)}{\text{\# of points won on return by i in match k}}}{\sum_{t=1}^{12}\sum_{k \in (i,y-1,m+t)}\text{\# of points played on return by i in match k}}$
\end{center}

Keeping consistent with this format, we also calculate $f_{av},g_{av}$ where $(y,m)$ represents the set of tour-level matches played in year $y$, month $m$:

\begin{center}
$f_{av}(y,m) = \frac{\sum_{t=1}^{12}\sum_{k \in (y-1,m+t)}{\text{\# of points won on serve in match k}}}{\sum_{t=1}^{12}\sum_{k \in (y-1,m+t)}\text{\# of points played in match k}} = 1 - g_{av}(y,m)$
\end{center}

Now, variance of $f_i,g_i$ no longer depends on time of year. Since the number of points won on serve are recorded in each match, we also know the player's number of serve/return points played. Below, we combine player statistics over the past 12 months to produce $f_{ij},f_{ji}$ for Kevin Anderson and Fernando Verdasco's 3rd round match at the 2013 Australian Open.

\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c| } 
 \hline
 player name & s\_points\_won & s\_points
&$f_i$ & r\_points\_won & r\_points & $g_i$ \\ 
 \hline
 Kevin Anderson & 3292 & 4842 & .6799 & 1726 & 4962 & .3478\\ 
 \hline
 Fernando Verdasco & 2572 & 3981 & .6461 & 1560 & 4111 & .3795\\ 
 \hline
\end{tabular}
\end{center}

From 2012 Australian Open statistics, $f_t=.6153$. From tour-level data spanning 2010-2017, $f_{av} = 0.6468; g_{av} = 1-f_{av} =.3532$ Using the above serve/return statistics from 02/12-01/13, we can calculate:

\begin{center}
$f_{ij} = f_t + (f_i-f_{av})-(g_j-g_{av}) = .6153 + (.6799-.6468) - (.3795-.3532) = .6221$
%\newline
$f_{ji} = f_t + (f_j-f_{av})-(g_i-g_{av}) = .6153 + (.6461-.6468) - (.3478-.3532) = .6199$
\end{center}

With the above serving percentages, Kevin Anderson is favored to win the best-of-five match with probability $M_p(0,0,0,0,0,0) = .5139$


\section{James-Stein Estimator}
Decades ago, Efron and Morris described a method to estimate groups of sample means \cite{EfronandMorris1977}. The James-Stein estimator shrinks sample means toward the overall mean, with shrinkage proportional to its estimator's variance. Regardless of the value of $\theta$, this method produces results superior in expectation to the MLE method, an admissible estimator.

To estimate serve/return parameters for players who do not regularly play tour-level events, $f_i,g_i$ must be calculated from limited sample sizes. Consequently, match probabilities based off these estimates may be skewed by noise. The James-Stein estimators offer a more reasonable estimate of serve and return ability for players with limited match history. 

%Players who do not regularly play tour-level events must yield serve and return estimates $f_i,g_i$ based on limited sample sizes. 

To shrink serving percentages, we compute the variance of all recorded $f_i$ statistics $\footnote{each ${f_i}$ is computed from the previous twelve months of player data}$ in our match data set $D_m$.

$\hat{\tau}^2 = \sum_{f_i \in D_m} (f_i-f_{av})^2$

Then, each estimator $f_i$ is based off $n_i$ service points. With each estimator $f_i$ representing $f_i/n_i$ points won on serve, we can compute estimator $f_i$'s variance and a corresponding normalization coefficient:

\begin{center}
\large{$\hat{\sigma_i}^2 = \frac{f_i(1-f_i)}{n_i}$}

\large{$B_i = \frac{\hat{\sigma_i}^2}{\hat{\tau}^2+\hat{\sigma_i}^2}$}
\end{center}

Finally, the James-Stein estimator takes the form: 

\begin{center}
$JS(f_i) = f_i + B_i(f_{av}-f_i)$
\end{center}

We repeat the same process with $g_i$ to obtain James-Stein estimators for return statistics.

To see how shrinkage makes our model robust to small sample sizes, consider the following example. When Daniel Elahi (COL) and Ivo Karlovic (CRO) faced off at ATP Bogota 2015, Elahi had played only one tour-level match in the past year. From a previous one-sided victory, his year-long serve percentage, $f_i=51/64=.7969$, was abnormally high compared to the year-long tour-level average of $f_{av}=.6423$. 


\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c|c| } 
 \hline
 player name & s\_points\_won & s\_points
 & $f_i$ & r\_points\_won & r\_points & $g_i$ & elo rating \\ 
 \hline
 Daniel Elahi & 51 & 64 & .7969 & 22 & 67 & .3284 & 1516.9178 
 \\
 \hline
 Ivo Karlovic & 3516 & 4654 & .7555 & 1409 & 4903 & .2874 & 1876.9545 \\ 
 \hline
\end{tabular}
\end{center}

\begin{center}
$f_{ij} = f_t + (f_i-f_{av})-(g_j-g_{av}) = .6676 + (.7969-.6423) - (.2874-.3577) = .8925$

$f_{ji} = f_t + (f_j-f_{av})-(g_i-g_{av}) = .6676 + (.7555-.6423) - (.3284-.3577) = .8101$
\end{center}

Following Klaassen and Magnus' method of combining player outcomes, we compute Elahi's service percentage to be $89.3\%$. This is extremely high, and eclipses Karlovic's $81.01\%$ serve projection. This is strange, given that Karlovic is one of the most effective servers in the history of the game. From the serving stats, our hierarchical Markov Model computes Elahi's win probability as $M_p(0,0,0,0,0,0) = .8095$. This forecast seems unreasonably confident of Elahi's victory, despite only having collected his player statistics for one match. Karlovic's 360-point elo advantage calculates Elahi's win probability as $$\hat{\pi}_{ij}(t) = (1+10^\frac{1876.9545 - 1516.9178}{400})^{-1} = .1459$$ which leads us to further question the validity of this approach when using limited historical data. Thus, we turn to the James-Stein estimator to normalize Elahi's serving and return probabilities.

\begin{center}
$JS(f_i) = f_i + B_i(f_{av}-f_i) = .7969 + .7117(.6423-.7969) = .6869$

$JS(g_i) = g_i + B_i(g_{av}-g_i) = .3284 + .7624(.3577-.3284) = .3507$

$JS(f_j) = f_j + B_j(f_{av}-f_j) = .7555 + .0328(.6423-.7555) = .7518$

$JS(g_j) = g_i + B_j(g_{av}-g_j) = .2874 + .0420(.3577-.2874) = .2904$

$JS(f_{ij}) = f_t + (JS(f_i)-f_{av})-(JS(g_j)-g_{av}) = .6676 + (.6869-.6423) - (.2904-.3577) = .7795$

$JS(f_{ji}) = f_t + (JS(f_j)-f_{av})-(JS(g_i)-g_{av}) = .6676 + (.7518-.6423) - (.3507-.3577) = .7841$

\end{center}

Above, we can see that the James-Stein estimator shrinks Elahi's stats far more than Karlovic's, since Karlovic has played many tour-level matches in the past year. Given $JS(f_i),JS(f_j)$, we compute $M_p(0,0,0,0,0,0) = .4806$. By shrinking the serve/return statistics, our model lowers Elahi's inflated serve percentage and becomes more robust to small sample sizes.

As point-based forecasts on limited data threaten model performance, especially with respect to cross entropy, the James-Stein estimator allows a safer way to predict match outcomes. Later on, we will use the James-Stein estimator to normalize not only year-long serve/return statistics, but also surface-specific and opponent-adjusted percentages.


%If Machado were to have lost against Tursunov, then our cross entropy would increase by $\approx 22$, a huge penalty for a single data point. Given Tursunov's elo advantage, this is not a situation to which we want to expose models forecasting. In the end, the James-Stein estimator offers robustness to serve/return probabilities derived from infrequently charted players. We will hold onto these estimates for use in future models.

\section{Opponent-Adjusted Serve/Return Statistics}

While Barnette and Clarke's equation does consider opponent's serve and return ability, it does not track average opponents' ability within a player's history. This is important, as a player's serve/return percentages may become inflated from playing weaker opponents or vice versa. In this section, we propose a variation to Barnette and Clarke's equation which replaces $f_{av},g_{av}$ with opponent-adjusted averages $1-g_{i\_opp\_av},1-f_{i\_opp\_av}$ for $p_i$. The equations then become:

\begin{center}
$f_{ij} = f_t + (f_i-(1-g_{i\_opp\_av}))-(g_j-(1-f_{j\_opp\_av}))$
%\newline
$f_{ji} = f_t + (f_j-(1-g_{j\_opp\_av}))-(g_i-(1-f_{i\_opp\_av}))$
\end{center}

$g_{i\_opp\_av}$ represents the average return ability of opponents that $p_i$ has faced in the last twelve months. To calculate this, we weight each opponent's return ability $g_j$ by number of points in their respective match.

\large{$g_{i\_opp\_av} = \frac{\sum_{t=1}^{12}\sum_{k \in (i,y-1,m+t)}{\text{(\# of $p_i$'s return points in match k)*($p_j$'s return ability in match k)}}}{\sum_{t=1}^{12}\sum_{k \in (i,y-1,m+t)}\text{\# of $p_i$'s return points in match k}}$}


\section{Results}
The following results were obtained from testing methods on 2014 ATP best-of-three matches, excluding Davis Cup. There were 2409 matches in this dataset. 

\subsection{Table}
We observe performance across variants of elo-based predictions and point-based models. Since all original implementations provide explicit formulas with no optimization, we directly assess their performance on 2014 tour-level match data. In the case of logistic regression, the model was trained on tour-level match data from 2011-2013. The following terms express variations to point-based and elo models:

\setlist[description]{leftmargin=\parindent, labelindent=\parindent}
\begin{description}[leftmargin=2.5cm, labelindent=2.5cm]
\item[KM] - point-based hierarchical Markov models with combined serve/return percentages from Barnett/Clarke

\item[James-Stein] - version of a KM model, with all serve/return percentages normalized with James-Stein estimator

\item[surface] - version of model where all ratings and percentages are stratified by surface (Hard, Clay, Grass)

\item[538] - specifically denotes Five-Thirty-Eight's ``decaying K-factor'' method in computing elo
\end{description}

\begin{center}
\begin{tabular}{ |c|c|c| } 
 \hline
 method & accuracy & log loss
   \\ 
 \hline
  KM & 64.8 & .649
  \\ 
 \hline
  KM James-Stein & 65.4 & .616
  \\ 
 \hline
 KM surface & 63.3 & .707
  \\ 
 \hline
 KM surface James-Stein & 63.6 & .639
  \\ 
 \hline
 KM adjusted & 67.8 & .632
  \\ 
 \hline
 KM adjusted James-Stein & 67.9 & .617
  \\ 
 \hline
  elo & 69.1 & .586
  \\ 
 \hline
 surface elo & 68.4 & .591
  \\ 
 \hline
 elo 538 & 69.2 & .587
  \\ 
 \hline
 surface elo 538 & 69.4 & .592
  \\ 
 \hline
 logit (elo 538, surface elo 538) & 69.5 & .577
  \\ 
 \hline
\end{tabular}
\end{center}

\subsection{Discussion}

As expected, James-Stein normalization significantly improves each point-based model's log loss. While surface-based elo is competitive with regular elo, restricting Klaassen and Magnus' point-based method to surface-specific data clearly hurts performance. This is presumably due to limited surface-specific data. As many players perform differently across surfaces, computing serve percentages from surface-specific data offers the potential to express how players' performance varies by surface. Yet, even with James-Stein normalization, the loss in sample size appears to outweigh the benefits obtained from surface-specific data. As we did not rigorously explore possibilities for weighting players' surface-specific statistics, there may still be potential for a point-based model that effectively considers surface in computing serve/return percentages. Finally, using opponent-adjusted serve-return statistics further improved performance. By fully incorporating each opponent's ability in a player's match history, this model approached elo ratings in likeness of predictions, with win-probability forecasts between the two sharing $R^2=.76$.

By plugging elo and surface elo into a logistic regression model, we achieve a log loss of .577. After fitting to the training data, this model learned coefficients for each variable that assigned a 56\% weight to regular elo ratings and 44\% weight to surface elo ratings. The near-even weight to both types of ratings suggests how important surface-specific ability is toward forecasting matches. Aside from models which draw information directly from the betting market, no other model has documented preferable log loss. Kovalchik reported 70$\%$ accuracy using 538's elo method \cite{Kovalchik2016}, calculating elo ratings using satellite events (ATP Challengers and Futures) in addition to tour-level events \footnote{one can observe at https://github.com/skoval/deuce}. While this accounted for a small increase in accuracy, her method achieved a log loss of .59, which does not outperform our implementation. For simplicity's sake, we calculated all elo ratings and statistics from tour-level matches alone \footnote{there are about 3000 tour-level matches each year}. In the end, our elo-based logistic regression's incremental improvement over singular elo ratings implies that an effective rating system should consider a overall ability as well as surface-specific ability.


%holds several implications. First, there is useful information about players contained in both surface-specific and non-surface elo ratings. Second, models that do not draw information from the betting market, no other tennis-specific methods have charted better performance \cite{Kovalchik2016}. 

%(you can attempt to combine both elo ratings with Gaussian processes or the hyperparameter hack)

Sipko recently explored machine-learning methods for pre-match prediction, surveying logistic regression, the common-opponent model, and an artificial neural net \cite{Sipko2015}. While he claimed to have achieved 4.3$\%$ return-on-investment off the betting market with an artificial neural net, his machine learning models did not beat a log loss of .61 when predicting 2013-2014 ATP matches \footnote{the models were trained on 2004-2010 ATP matches and validated on 2011-2012 ATP matches}. Despite the current deep-learning craze throughout industry and academia (cite nyt article), no one has published findings to suggest their superiority in predicting tennis matches. Short of market-based models, it appears most effective to stick with elo's ``ruthlessly Bayesian design'' which Five-Thirty-Eight so frequently touts (cite: article). Transitioning onward, we will consider how these findings may inform an effective in-match prediction model.


%As Sipko surveyed logistic regression, the common-opponent model, and an artificial neural net, we are confident that elo provides a confident starting place for in-match prediction models.

%The question becomes, how can this serve our in-match predictions?

%It is important to note that Klaassen and Magnus' method of combining player statistics involves no optimization with respect to a training dataset. Of the above methods, only a logistic regression with elo and surface elo actually learns its model parameters with respect to a training dataset. 



\chapter{In-game Match Prediction}

%Having surveyed all relevant pre-match prediction models, we proceed to in-match prediction. 

The following methods will be tested on tour-level matches for which we have point-by-point data. The matches span 2010-2017, accounting for nearly half of all tour-level matches within this time. Point-by-point records in Sackmann's dataset take the form of the following string:

Mikhail Youzhny vs. Evgeny Donskoy (Australian Open 2013, Round 2)

P=\seqsplit{``SSRSS;RRRR;SRSSS;SRRSRSSS;SRSSRS;RSRSSS;SRSRSS;RSRSRSSS;SSSS.SSSRRRSS;RSSSS;SSRSS;SSSRS;SSSS;RRRSSSSRRSSRRSRSSS;SRSRSS;SSSRS;RSRSSRSS;SSSS;SRSSS;RSRSSRRSSS;R/SR/SS/RR/RS/SR.RSRRR;...''}

$S$ denotes a point won by the server and $R$ a point won by the returner. Individual games are separated by ``$;$'' sets by ``$.$'' and service changes in tiebreaks by ``$/$''. By iterating through the string, one can construct $n$ data points $\{P_0,P_1,...,P_{n-1}\}$ from a match with $n$ total points, with $P_i$ representing the subset of the match after which $i$ points have been played.

$P_0 = ``"$

$P_1 = ``S"$

$P_2 = ``SS"$

$P_3 = ``SSR"$

...

With $M = \{M_1,M_2,...M_k\}$ representing complete match-strings in our point-by-point data set, the size of our enumerated data set becomes $\sum_{i=1}^k |M_i|$. In total, this sums to 1,231,122 individual points within ATP matches spanning 2010-2017. While many in-match prediction models utilize the hierarchical Markov Model structure, we will first test several machine-learning methods as a baseline.

%we may apply serving percentages from the past section to in-match prediction. To start, 

\section{Logistic Regression}

Consider a logistic regression model where each input $x_i = [x_{i1},x_{i2},...,x_{ik}]$ has $k$ features. $logit(x_i)$ yields $p_i$'s win probability from input $x_i$,

$$logit(x_i) = \frac{1}{1+e^{-(\beta_0+\beta_1(x_{i1})+\beta_1(x_{i2})+...+\beta_1(x_{ik}))}}$$

From any scoreline ($s_i,s_j,g_i,g_j,{x}_i,{x}_j$), we can simply feed these values into our model as features of $x_i$ (change notation?). Logistic Regression's structure makes it easy to consider additional features for each player, such as elo difference, surface elo difference, or break advantage. Before adding more features to the model, we consider two baselines: a model using score differentials ($s_i-s_j,g_i-g_j,{x}_i-{x}_j$) and another model trained on elo differences and lead heuristic $L_{ij}$.

This heuristic estimates one $p_i$'s total lead in sets, games, and points:

$L_{ij} = (s_i-s_j) + \frac{1}{6}(g_i-g_j) + \frac{1}{24}(x_i-x_j)$

The coefficients preserve order between sets, games, and points, as one cannot lead by six games without winning a set or four points without winning a game. In this model, we consider the following features for prediction:

\begin{table}[H]
\centering
\caption{Logistic Regression Features}
\label{my-label}
\begin{tabular}{ll}
 \hline
 $Variable$ & $Description$ \\
 \hline
 lead\_margin & lead heuristic $L_{ij}$ \\
 \hline
 eloDiff &  Elo($p_0$) - Elo($p_1$) \\
 \hline
  s\_eloDiff &  s\_Elo($p_0$) - s\_Elo($p_1$) \\
 \hline
 setDiff &  SetsWon($p_0$) - SetsWon($p_1$)\\
 \hline
 gameDiff &  inSetGamesWon($p_0$) - inSetGamesWon($p_1$)\\
 \hline
 pointDiff &  inGamePointsWon($p_0$) - inGamePointsWon($p_1$)\\
 \hline
  breakAdv &  ServeGamesWon($p_0$) - ServeGamesWon($p_1$) + I(currently serving)\\
 \hline
 brkPointAdv & I(holding break point) - I(facing break point)\\
 \hline
 sv\_points\_pct\_0 & percentage of points won on $p_0$'s serve thus far\\
 \hline
 sv\_points\_pct\_1 & percentage of points won on $p_1$'s serve thus far\\
 \hline
\end{tabular}
\end{table}

Next, we test the following combinations of features:

1) setDiff + gameDiff + pointDiff

2) lead\_margin + eloDiff + s\_eloDiff

3) all features

\subsection{Cross Validation}

Each match in our best-of-three dataset has around 160 points on average. In tuning hyper parameters for machine learning models, we implement five-fold group validation. By grouping points from the same match together, this method prevents overlap between points from the same match across train, validation, and test sets. Then, performance on a test set truly reflects performance on matches a model has never seen before. 

%prevents information within a single match from informing the model before we test performance on other points from the same match. 

%(actually didn't do hyperparameter cross-validation because it seemed unnecessary...)

%\subsection{Visualizing Logistic Regression ??? here???}


%\includegraphics[scale=.7]{gasquet_reister_9_6_all_features}

%One drawback of logistic regression is that it cannot distinguish between situations whose score differentials are equivalent. A player serving at (1,1),(5,4),(3,0) will have approximately the same win probability as one serving at (1,1),(1,0),(3,0). However, in the first situation, the player serving wins the match if he wins any of the next three points. From the second scenario, the player serving only holds a break advantage early in the set, from which the returner has many more chances to come back. Assuming each player serves at $f_i=f_j=.64$, our win-probability equation suggests a substantial difference between these two scenarios:

%\begin{center}
%$P_m(1,1,5,4,3,0) = .994$

%$P_m(1,1,1,0,3,0) = .800$
%\end{center}

%Although the first situation is clearly favorable, logistic regression will compute approximately the same probability in both scenarios $\footnote{\text{after fitting coefficients for the equation P(win) = logit($s_i,s_j,g_i,g_j,{x}_i,{x}_j)= \frac{e^{(c_1s_i+c_2s_j+c_3g_i+c_4g_j+c_5x_i+c_6x_j}}{1+e^{(c_1s_i+c_2s_j+c_3g_i+c_4g_j+c_5x_i+c_6x_j}}$}, coefficients $ c_1 \approx c_2, c_3 \approx c_4,c_5 \approx c_6$ by symmetry and therefore $logit(1,0,5,4,3,0) \approx logit(1,0,1,0,3,0) $}$

%$\footnote{after fitting coefficients for the equation $P(win) = logit(s_i,s_j,g_i,g_j,{x}_i,{x}_j) = \frac{e^{(c_1s_i+c_2s_j+c_3g_i+c_4g_j+c_5x_i+c_6x_j}}{55}$, coefficients $ c_1 \approx c_2, c_3 \approx c_4,c_5 \approx c_6$ by symmetry and therefore}$

%Another issue is that logistic regression can fail to detect when a higher-ranked player is about to lose in a close match. Below,

%\includegraphics[scale=.7]{simon_gabashvili_9_6_all_features}

%Simon leads for most of the match until Gabashvili comes back to force the third set. At the end of the third set, Gabashvili serves out the match from 5-4, yet the model fails to detect that Simon is about to lose. This is because, with sets at 1-1 and game differentials nearly even, Simon's elo advantage outweighs his current scoreline disadvantage. Consequentially, his win-probability hovers between 40-50\% as he loses the match, rather than fall toward 0.


\section{Random Forests}
Brian Burke's win-probability models are among the most well-known in sports \cite{Burke2014}. They calculate a team's win probability at any point in the match based on historical data through a combination of binning inputs and smoothing their resulting probabilities. Nettleton and Lock built on this method by using a random forest approach.

A random forest consists of an ensemble of randomly generated classification trees. Each tree forms decision functions for a subset of features with splits that generate maximum discriminatory ability. As Nettleton and Lock do so with football-specific features such as down, points, and yards to goal, we do so with analogous tennis features and train on our validation set.

%Nettleton and Lock also deviate from the traditional random forest classification problem in using regression trees and averaging their estimates to produce a probability estimate, rather than a majority vote.

%Then, training on our validation set, we test two random forest models on our point-by-point dataset, one with classification trees and one with regression trees.

\begin{table}[H]
\centering
\caption{Random Forest features}
\label{my-label}
\begin{tabular}{ll}
 \hline
 Variable & Description \\
 \hline
 surface & hard, clay, grass \\
 \hline
 set &  first, second, third \\
 \hline
 eloDiff &  Elo($p_0$) - Elo($p_1$) \\
 \hline
  setDiff &  SetsWon($p_0$) - SetsWon($p_1$)\\
 \hline
 gameDiff &  inSetGamesWon($p_0$) - inSetGamesWon($p_1$)\\
 \hline
 pointDiff &  inGamePointsWon($p_0$) - inGamePointsWon($p_1$)\\
 \hline
  breakAdv &  ServeGamesWon($p_0$) - ServeGamesWon($p_1$) + I(currently serving)\\
 \hline
 brkPointAdv & I(holding break point) - I(facing break point)\\
 \hline
\end{tabular}
\end{table}

\section{Hierarchical Markov Model}
With serving percentages already calculated from historical data, our hierarchical Markov model is well-equipped to produce in-match win probability estimates. Using the analytical equation with players' serving abilities $f_{ij},f_{ji}$, we compute $P_m(s_i,s_j,g_i,g_j,x_i,x_j)$ from every scoreline $(s_i,s_j,g_i,g_j,x_i,x_j)$ in a match. To assess this model's performance, we repeat this on every match in our dataset, with $f_{ij},f_{ji}$ computed with one's method of choice.

\subsection{Beta Experiments}
The above approach only takes into account the current score and pre-calculated serve percentages when computing win probability. However, in many cases, relevant information may be collected from $P_k$. Consider the following in-match substring, 

$P=``SSSS;RSSSRRSS;SSSS;SRRSRSRSSS;SSSS;RRRSSSRSRSSS;"$

The above sequence demonstrates a current scoreline of three games all. However, $p_i$ has won 12/12 service points, while $p_j$ has won 18/30 service points. If both players continue serving at similar rates, $p_i$ is much more likely to break serve and win the match. Since original forecasts are $f_{ij},f_{ji}$ are based on historical serving percentages, it makes sense that in-match serving percentages may help us better determine each player's serving ability on a given day. To do this, we can update $f_{ij},f_{ji}$ at time $t$ of the match to factor in each player's serving performance thus far.

Bevc explored this method by modeling each player's serving percentage $f_{ij}$ with a beta prior $b_{prior}$ that could be updated mid-match to yield posterior estimates. Through beta-binomial conjugacy, we can update $b_{prior}$ when a player has won $s_{won}$ points on serve out of $s_{total}$ trials.

\begin{center}
$b_{prior} \sim \text{Beta}(a,b)$ 

$b_{posterior} \sim \text{Beta}(a+s_{won},b+s_{total}-s_{won})$
\end{center}

%The beta distribution is a generalization of the uniform distribution. We often use the beta distribution to represent prior and posterior estimates of some unknown probability $p$. (can include stats notation with beta-binomial conjugacy)

If $f_{ij}$ is our prior, $a,b$ must satisfy $E(b_{prior}) = \frac{a}{a+b} = f_{ij}$. Then $a$ is a hyperparameter that determines the strength of our prior. To find a suitable prior strength, we will test various values of $a$ via cross-validation on our training set. Regardless of $a$, the match's influence on our posterior serve estimates always grows as more points have been played. At any point in the match, we can always obtain a posterior serving percentage for either player of the form

$f_{ij}' = E(b_{posterior}) = \frac{a + s_{won}}{a + b + s_{total}}$


%To update our matches with in-match serving statistics, we set $f_{ij}$ as a prior and update with the number of points won and played on $p_i's$ serve, $(s_{won},s_{pt})$. 

\subsection{Elo-induced Serve Probabilities}
Earlier on, Klaassen and Magnus suggested a method to infer serving probabilities from a pre-match win forecast $\pi_{ij}$. By imposing a constraint $f_{ij}+f_{ji}=t$, we can then create a one-to-one function 
$S: S(\pi_{ij},t) \rightarrow (f_i,f_j)$, which generates serving probabilities $\hat{f_{ij}},\hat{f_{ji}}$ for both players such that $P_{m}(0,0,0,0,0,0)=\pi_{ij}$ \footnote{$f_{ij}$ and $f_{ji}$ are computed as specified in 3.4 with James-Stein normalization, so as to prevent extreme results}. As this paper was published in 2002, Klaassen and Magnus inverted their match probability equations to produce serve probabilities for ATP rank-based forecasts. However, since elo outperforms ATP rank, we apply this method to elo forecasts.

Due to branching complexity (see section 2.5), our hierarchical Markov model's match probability equation has no analytical solution to its inverse, even when we specify $f_{ij}+f_{ji}=t$. Therefore, we turn to the following approximation algorithm to generate serving percentages that correspond to a win probability within $\epsilon$ of our elo forecast's:

\begin{algorithm}[H]
\caption{elo-induced serve probabilities}\label{euclid}
\begin{algorithmic}[H]
\Procedure{EloInducedServe(prob,sum,$\epsilon$)}{}
\State $\text{s0} \gets \text{sum/2}$
\State $\text{currentProb} \gets \text{.5}$
\State $\text{diff} \gets \text{sum/4}$

\While {$|$currentProb - prob$| > \epsilon $}:

\If {$\text{currentProb \textless$ $ prob}$}
\State s0 += diff 
\Else
\State s0 -= diff
\EndIf
\State diff = diff/2
\State $\text{currentProb} \gets \text{matchProb(s0,sum-s0)}$

\EndWhile


\State \Return s0, sum-s0

\EndProcedure
\end{algorithmic}
\end{algorithm}

To generate elo-induced serve probabilities for a given match, we run the above algorithm with PROB=$\pi_{ij}$, SUM=$f_{ij}+f_{ji}$, and $\epsilon$ set to a desired precision level $\footnote{for purposes of this project, setting $epsilon$=.001 is sufficiently accurate}$. At each step, we call matchProb() to compute the win probability from the start of the match if $p_i$ and $p_j$ had serve probabilities $f_{ij}=s0, f_{ji}=\text{sum}-s0$, respectively. Then we compare currentProb to prob and increment s0 by diff, which halves at every iteration. This process continues until the serve probabilities s0, sum-s0 produce a win probability within $\epsilon$ of PROB, taking $O(\log{\frac{1}{\epsilon}})$ calls to matchProb.

This inverse algorithm is useful for several reasons. Given any effective pre-match forecast $\pi_{ij}$, we can produce serve probabilities that are consistent with $\pi_{ij}$ according to our hierarchical Markov model. By setting the constraint $f_{ij}+f_{ji}=t$, we also ensure that the sum of our players' serve probabilities agrees with historical data. While Klaassen and Magnus argue that $t = f_{ij}+f_{ji}$ is largely independent of $\pi_{ij}$, $t$ holds greater importance when predicting specific score lines a match \cite{Barnett2006}. Using the hierarchical Markov Model's equations, Barnette specifically computed the probability of reaching any set score given $f_{ij},f_{ji}$. When comparing probabilities across matches, one can observe that as $t$ increases, closer set scores and tie-break games become more likely \footnote{``closer'' scores meaning 7-6, 6-7, 7-5, 5-7, etc.}. That is, $t$ encodes information regarding likely trajectories of a match scoreline and relative importance of winning each game on serve. For higher $t$, service games are won more often and service breaks hold relatively more importance, while the opposite holds for lower $t$. Now, given $\pi_{ij}$ and $t$, we can produce elo-induced serve probabilities for any two players.

%\footnote{to avoid extreme values of $t$ from limited player data, we use James-Stein normalized estimates to calculate $t$: $t = JS(f_{ij})+JS(f_{ji})$}



\subsection{Significance of $f_{ij}+f_{ji}$}

To illustrate the importance of $t=f_{ij}+f_{ji}$, we consider the two following matches:

\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c| } 
 \hline
 match & $p_i$ & $p_j$ & tny\_name & surface
 & $\pi_{ij}$ & $t$ \\ 
 \hline
 $m_1$ & Feliciano Lopez & John Isner & ATP Shanghai 2014 & hard & .478 & 1.55 \\
 \hline
  $m_2$ & Andreas Seppi & Juan Monaco & ATP Kitzb$\ddot{\text{u}}$hel 2014 & clay & .476 & 1.14
 \\
 \hline

\end{tabular}
\end{center}

In both matches, $\pi_{ij}$ is approximately the same while $t$ differs significantly. To visualize how service breaks can have varying importance, consider win-probability graphs corresponding to the following progression of points, $P$. In each scenario, $p_i$ and $p_j$'s serve probabilities are calculated from method 4.3.2.

$P=``SSSS;SSSS;SSSS;SSSS;SSSS;RRRR"$

\includegraphics[scale=.7]{m12_wp}

Over the first five games, both players win every point on serve. When $t=1.55$, service holds are expected and and win probability hardly moves. After $p_i$ breaks serve in the sixth game, his win probability suddenly spikes up, indicating a substantial advantage. When $t=1.14$, our model assumes that players win service games with much lower probability. Therefore, each time a player holds serve, his win probability noticeably increases. When $p_i$ breaks in the sixth game, his win probability climbs, but not as dramatically as in the previous case. When service games are won at a lower probability, service break advantages become weaker.

$t$'s influence on the trajectory of a match suggests that prediction from any in-match scoreline will be most effective when $t$ accurately reflects the players' overall serving ability. While elo ratings or betting odds yield the most effective pre-match predictions \cite{Kovalchik2016}, their implied odds offer no information about $t$ in a given match-up. As $t$ holds significance for in-match forecasting from specific scorelines, method 4.3.2 allows us to combine any effective pre-match forecast $\pi_{ij}$ with $t$ to produce new serving probabilities.

%To preserve information about the shape of each match, we set the constraint $t = f_{ij}+f_{ji}$, rather than some constant $k = f_{av}+g_{av}$.

%Examples: Federer vs Isner at Paris (or Karlovic vs Isner for more even match), then Ferrer vs. Nishikori/Schwartzman or something with really good returners. (can visualize this with new win probabilities, use example when Karlovic and Schwartzman both had the same win probability)

% write about importance on shape of match


%Take two matches with $\pi_{1ij} \approx \pi_{2ij}$. Then graph the matches' WP with respect to a made-up scoreline that includes one service break.

%Since elo ratings fail to capture this, it is crucial that we find a way to incorporate this into our model.

%show a histogram of $t$ (?):

\section{Results}

The following models were trained on 4584 matches from 2011-2013 and tested on 1855 matches from 2014 in our point-by-point data set. From cross-validation on the training set, we determined that setting hyper-parameter $a=300$ yielded optimal performance across beta experiments. We then added a beta variation to KM elo-induced and KM logit-induced, our two best-performing point-based models.

\setlist[description]{leftmargin=\parindent, labelindent=\parindent}
\begin{description}[leftmargin=2.5cm, labelindent=2.5cm]
\item[LR] - Logistic Regression model with feature set specified in 4.1

\item[Random Forest] - Random Forest model with feature set specified in 4.2

\item[Equivalent] - KM model with serve probabilities set to tour-level averages (assumes equal player ability)

\item[elo-induced] - KM model with serve probabilities generated from elo-based win probability

\item[logit-induced] - KM model with serve probabilities generated from logistic regression on elo and surface-based elo
\end{description}


\begin{center}
\begin{tabular}{ |c|c|c|c| } 
 \hline
 method & accuracy & log loss & calibration
   \\ 
 \hline
  LR 1) & 71.4 & .540 & .993
  \\ 
 \hline
  LR 2) & 75.2 & .505 & 1.006
  \\ 
 \hline
 LR 3) & 76.2 & .488 & .993
  \\ 
 \hline
 Random Forest & 70.1 & .562 & .902
  \\ 
 \hline
 KM Equivalent & 71.5 & .538 & 1.040
  \\ 
 \hline
 KM James-Stein & 74.9 & .501 & 1.002
  \\ 
 \hline
 KM adjusted James-Stein & 75.9 & .498 & .992
  \\ 
 \hline
 KM elo-induced & 76.2 & .486 & 1.001
  \\ 
 \hline
  KM elo-induced (a=300) &  & &
  \\ 
 \hline
  KM logit-induced & 76.5 & .481 & .996
  \\ 
 \hline
 KM logit-induced (a=300) & 76.5 & .477 & .999
  \\ 
 \hline
\end{tabular}
\end{center}

Of our models, Random Forest had the least predictive power. While this is perhaps due to difficulty in constructing an effective feature space, nearly all features fed into each machine learning model had an additive effect on win probability. Positive score differentials, break advantages, and elo differences will all boost a player's expected win probability. The only non-additive features we considered were ``set'' and ``surface''. While the random forest model was able to consider various situations among these two features, we conclude that its inclination to group similar examples together, rather than estimate linear relationships between variables, ultimately accounted for its performance.

Logistic regression, on the other hand, is designed to  learn additive relationships between features and its probability output. It's performance with the full feature set was competitive with our point-based models, despite their superior grasp of tennis' scoring system \footnote{consider, for example, how our logistic regression has no idea what a tiebreak game is}. Presumably, this model holds an advantage over point-based models in its ability to fit itself to the training data. Aside from our hyper-parameter search of $a$ in beta experiments, the point-based models offer no comparable method to optimize performance with respect to a training set.

%When we consider prediction models for tennis, we want the following condition to hold: for any score line $(s_i,s_j,g_i,g_j,{x}_i,{x}_j)$, a suitable model with formula $P_m$ should produce win probability such that $P_m(s_i,s_j,g_i,g_j,{x}_i+1,{x}_j) > P_m(s_i,s_j,g_i,g_j,{x}_i,{x}_j)$. That is, at any stage in the match, $p_i$'s win probability should always increase after winning the next point. While there are no guarantees of maintaining this property with machine learning models, our point-based model will satisfy this condition without fail. \footnote{section 2.5 verifies this}

Of the point-based models, KM logit-induced (a=300) achieved the best performance, although the improvement from running beta experiments with a=300 was marginal. Since elo ratings produce more reliable pre-match win forecasts $\pi_{ij}$ than estimates of $f_{ij},f_{ji}$ from historical serve/return data, using serve probabilities induced from elo ratings and then from our logit elo model improved our models performance by significant increments. Over the next few sections, we will examine our models' calibration and performance across subsets of our dataset.

%Interestingly, logistic regression with our complete feature set performed nearly as well as our best variation of the KM point-based model. Despite issues discussed in 4.1.2, logistic regression can still perform nearly as well ase the best of our point-based models.

\subsection{Model Calibration}

\hspace*{-.5cm}\includegraphics[scale=.6]{calibration_plot}

Calibration represents the ratio between observed rate of success and mean predicted rate of success. From a perfectly calibrated model that predicts a win probability of $p$, we can always expect a win to occur with probability $p$. While the Random Forest model under-predicted wins, the rest of our models closely resemble a perfectly calibrated model. From our table, KM logit elo and KM JS exhibited near-perfect calibration of 1.001 and .999, while logistic regression reported .993. As there is degree of uncertainty in measuring calibration, we could not reasonably expect to produce more well-calibrated models. Given win probability forecast $\pi_{ij}$ at any point in the match, we expect $p_i$ to win with probability $\pi_{ij}$.

\subsection{By Set}

to do: display uncertainty lines on each bar?? not sure if this is meaningful?

\hspace*{-1.5cm}\includegraphics[scale=.6]{set_performance}

Across both metrics, models are most effective during the second set. At this point in the match, the winner of the first set is often a clear favorite to win the match, unless their opponent has a significantly higher elo rating or service ability. As 64.3\% of matches in our test set are straight-sets victories \footnote{matches that end in two sets are straight-sets}, these matches offer relatively easy predictions for our model.

Uncertainty increases once the match enters a third set because the set score has evened at 1-1. While the set score is tied in both first and third sets, it is easier to predict the outcome during the third set because its outcome corresponds directly to the match outcome. When predicting in the first set, the player who wins the first set can still go on to lose the match, which increases uncertainty.

%If we are equally confident in predicting P(win current set) across all sets, then P(win | current set) = 1 in third set while P(win | current set) is less certain in the first set. Discuss how performance differs by set (1st, 2nd, 3rd) From a favorable position in the third set, one is more likely to win the match since winning the first set does not clinch the match.


\subsection{By Surface}

\hspace*{-1.5cm}\includegraphics[scale=.6]{surface_performance}

Zoom in on graphs. 

By surface, models predicted grass court matches most effectively while clay court matches proved more difficult. By nature, grass courts are faster and conducive to offensive play. Since service games are held at a higher rate, break advantages can be more decisive, which likely gave all models an edge when predicting outcomes from all scorelines. On the other hand, clay courts suit defensive play and often give rise to more service breaks. When service breaks are more likely, it becomes harder for our models to predict the match because advantages from a current score line are more likely to be turned around. Hard courts, where the majority of matches took place, ultimately proved in between grass and clay in its predictability. Further insight into the volatility of matches \footnote{we may calculate a measure of volatility from point-by-point sequences or a model's win probability output} across surfaces may explain differing results across surfaces.

\subsection{Distribution of Performance}

show a histogram of log loss scores, accuracy scores by match



\subsection{Variable Importance}

Discuss relative variable importance among features in the most effective LR model. Talk about how these features relate to the point-based model or how there may be features with information the point-based model lacks (likely not, since I crafted features to represent scenarios which are embedded in the point-based model, like break point, etc). serve percentages could be analogous to beta experiments

graph LR and KM together, commenting how LR jumps around more

(from points and game increases, this is a matter of reactivity from correlation vs causality; lr is somewhat reacting to jumps because having a point lead is going to be more associated with winners.)

\section{Visualizing Win Probability}

TO DO: Compare/contrast the two models, provide year/tournament info for each match

\includegraphics[scale=.7]{reister_gasquet}

One drawback of logistic regression is that it cannot distinguish between situations whose score differentials are equivalent. A player serving at (1,1),(5,4),(3,0) will have approximately the same win probability as one serving at (1,1),(1,0),(3,0). However, in the first situation, the player serving wins the match if he wins any of the next three points. From the second scenario, the player serving only holds a break advantage early in the set, from which the returner has many more chances to come back. Assuming each player serves at $f_i=f_j=.64$, our win-probability equation suggests a substantial difference between these two scenarios:

\begin{center}
$P_m(1,1,5,4,3,0) = .994$

$P_m(1,1,1,0,3,0) = .800$
\end{center}

Although the first situation is clearly favorable, logistic regression will compute approximately the same probability in both scenarios $\footnote{\text{after fitting coefficients for the equation P(win) = logit($s_i,s_j,g_i,g_j,{x}_i,{x}_j)= \frac{e^{(c_1s_i+c_2s_j+c_3g_i+c_4g_j+c_5x_i+c_6x_j}}{1+e^{(c_1s_i+c_2s_j+c_3g_i+c_4g_j+c_5x_i+c_6x_j}}$}, coefficients $ c_1 \approx c_2, c_3 \approx c_4,c_5 \approx c_6$ by symmetry and therefore $logit(1,0,5,4,3,0) \approx logit(1,0,1,0,3,0) $}$

%$\footnote{after fitting coefficients for the equation $P(win) = logit(s_i,s_j,g_i,g_j,{x}_i,{x}_j) = \frac{e^{(c_1s_i+c_2s_j+c_3g_i+c_4g_j+c_5x_i+c_6x_j}}{55}$, coefficients $ c_1 \approx c_2, c_3 \approx c_4,c_5 \approx c_6$ by symmetry and therefore}$

Another issue is that logistic regression can fail to detect when a higher-ranked player is about to lose in a close match. Below,

\includegraphics[scale=.7]{simon_gabashvili}

Simon leads for most of the match until Gabashvili comes back to force the third set. At the end of the third set, Gabashvili serves out the match from 5-4, yet the model fails to detect that Simon is about to lose. This is because, with sets at 1-1 and game differentials nearly even, Simon's elo advantage outweighs his current scoreline disadvantage. Consequentially, his win-probability hovers between 40-50\% as he loses the match, rather than fall toward 0.



\chapter{Conclusion}

For the first time, we have documented the performance of in-match prediction methods on thousands of matches. While previous work only applied methods to individual matches or the 1992-1995 Wimbledon match data set \cite{KlaassenandMagnus2003}, we have applied methods to thousands of matches from the past several years. Results from this project and Jeff Sackmann's point-by-point dataset should serve as an appropriate benchmark for future work in this field.

%future work regarding in-match prediction, we have established a benchmark and data set against which to test prediction methods.

Although many papers have referenced Klaassen and Magnus' point-based model, none has explicitly outlined a way to correct for uncertainty stemming from small sample sizes in players' serve/return history. Applying a normalization method, such as the James-Stein estimator in 3.5, significantly boosts the performance of point-based models. By factoring in the overall ability of a player's opponents in the past twelve months, calculating $f_{ij},f_{ji}$ from the opponent-adjusted method in 3.6 offers additional predictive power. Still, none of these variations produce pre-match forecasts as effectively as elo ratings. Using our approximation algorithm in 4.3.2, we can derive serve probabilities from any pre-match forecast $\pi_{ij}$ and historical serve parameter $t = f_{ij} + f_{ji}$. A combination of this method, using $\pi_{ij}$ derived from an elo-based logistic regression, ultimately produced the most reliable in-match prediction model.

Finally, logistic regression's performance with a score-based feature set proved noteworthy. Machine-learning models offer potential in their ability to learn from a training set. While serve parameters $f_{ij},f_{ji}$ may be obtained from a machine-learning model's forecast, $\pi_{ij}$, our traditional point-based hierarchical Markov Model offers no comparable method to ``train'' itself from a dataset. Future work with point-based models that offers some aspect of optimization on a training set may be of much interest to fans and bettors alike.

\section{Real-World Applications}

Methods explored in this project may be applied to betting markets in several ways. First, we can take any pre-match forecast, $\pi_{ij}$, derived from implied market odds and produce corresponding serve probabilities $f_{ij},f_{ji}$ from method 4.3.2. As Kovalchik found that the Bookmaker Consensus Model outperformed elo ratings \cite{Kovalchik2016}, we could likely further improve performance of in-match prediction models by using pre-match betting odds. Next, we may back test any of our in-match prediction techniques against historical in-match odds. While Betfair offers historical data, all market data is time-stamped and lacks corresponding match scores. While mapping time-stamps to their corresponding score lines over thousands of matches proved outside the scope of this project, analyses with in-match betting data do exist, as when Huang demonstrated score inference from betting odds \cite{Huang2011}. Finally, one may also test betting strategies with any of these models in real time, provided you have up-to-date information to produce elo ratings and $f_{ij},f_{ji}$.

There are many advances yet to come in forecasting in-game win probability of tennis matches. Aside from beta experiments, all point-based models in this paper operated under the assumption that points played by each server are iid. While Klaassen and Magnus concluded that deviations from iid are small enough for such models to provide a reasonable approximation \cite{KlaassenandMagnus2001}, there is clearly much more work to be done in this area. Tracking a player's momentum at any point in the match, and updating serve probabilities accordingly, may also allow us to improve our models.


%This project was intended to lay a foundation for in-match prediction. By testing models on 

\section{Future Steps}

\section{Visualizing Grand Slam Matches}

Earlier this year, Roger Federer overcame Rafael Nadal in the Australian Open final 6-4 3-6 6-1 3-6 6-3. Below, we view a win-probability graph corresponding to our LR 3) and KM logit-induced (a=300) models.

\subsection{Roger Federer vs. Rafael Nadal Australian Open 2017 Final}

\includegraphics[scale=.7]{federer_nadal_ao_17}


\subsection{Novak Djokovic vs. Roger Federer US Open 2011 Semi-Final}

One of the most famous comebacks in tennis history. Djokovic recovered from a two-set deficit before escaping defeat at 3-5 15-40 on Federer's serve in the final set \footnote{if one were to consider Djokovic's decision to hit an all-or-nothing return winner at 3-5 15-40 in the fifth set, we could have computed his win probability to be even less than $p=.015$, as Federer would have surmised \url{https://www.theguardian.com/sport/2011/sep/11/us-open-2011-federer-djokovic}. Calculating in-match win probability within points based on shot-selection is realistic nowadays, thanks to Jeff Sackmann's match charting project and recent data analyses with Hawkeye ball-tracking data, and a logical extension to our point-by-point models}.

\includegraphics[scale=.7]{djokovic_federer_uso_11}




\bibliographystyle{plain}
\bibliography{references}

\end{document}