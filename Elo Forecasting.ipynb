{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# determine the optimal pre-match forecast, given elo_diff and s_elo_diff\n",
    "# step 2: calculate glicko and s_glicko for each player and do the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_id</th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>tourney_date</th>\n",
       "      <th>p0_name</th>\n",
       "      <th>p1_name</th>\n",
       "      <th>p0_elo</th>\n",
       "      <th>p1_elo</th>\n",
       "      <th>elo_diff</th>\n",
       "      <th>p0_s_elo</th>\n",
       "      <th>p1_s_elo</th>\n",
       "      <th>...</th>\n",
       "      <th>p0_r_pct_JS</th>\n",
       "      <th>p1_52_rwon</th>\n",
       "      <th>p1_52_rpt</th>\n",
       "      <th>p1_r_pct</th>\n",
       "      <th>p1_r_pct_JS</th>\n",
       "      <th>tourney_stats</th>\n",
       "      <th>best_of</th>\n",
       "      <th>score</th>\n",
       "      <th>pbp</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-375</td>\n",
       "      <td>Montpellier</td>\n",
       "      <td>2010-10-25</td>\n",
       "      <td>Romain Jouan</td>\n",
       "      <td>Taylor Dent</td>\n",
       "      <td>1519.128216</td>\n",
       "      <td>1720.828131</td>\n",
       "      <td>-201.699915</td>\n",
       "      <td>1517.563000</td>\n",
       "      <td>1669.753884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343856</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2182.0</td>\n",
       "      <td>0.343721</td>\n",
       "      <td>0.344525</td>\n",
       "      <td>0.66189</td>\n",
       "      <td>3</td>\n",
       "      <td>6-7 6-3 6-4</td>\n",
       "      <td>SSSS;SSSS;SSSS;SSSS;SSSS;SRRSSS;RRSSRSSS;SSSS;...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-375</td>\n",
       "      <td>Montpellier</td>\n",
       "      <td>2010-10-25</td>\n",
       "      <td>Julian Reister</td>\n",
       "      <td>Richard Gasquet</td>\n",
       "      <td>1574.319533</td>\n",
       "      <td>1948.840391</td>\n",
       "      <td>-374.520858</td>\n",
       "      <td>1472.470266</td>\n",
       "      <td>1839.154165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353614</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>4348.0</td>\n",
       "      <td>0.373505</td>\n",
       "      <td>0.372607</td>\n",
       "      <td>0.66189</td>\n",
       "      <td>3</td>\n",
       "      <td>6-7 6-3 6-3</td>\n",
       "      <td>SSSS;SSSS;SSSS;SSSS;SSSS;SSSS;SSSS;SSSS;SSRRSR...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  tourney_id tourney_name tourney_date         p0_name          p1_name  \\\n",
       "0   2010-375  Montpellier   2010-10-25    Romain Jouan      Taylor Dent   \n",
       "1   2010-375  Montpellier   2010-10-25  Julian Reister  Richard Gasquet   \n",
       "\n",
       "        p0_elo       p1_elo    elo_diff     p0_s_elo     p1_s_elo   ...    \\\n",
       "0  1519.128216  1720.828131 -201.699915  1517.563000  1669.753884   ...     \n",
       "1  1574.319533  1948.840391 -374.520858  1472.470266  1839.154165   ...     \n",
       "\n",
       "   p0_r_pct_JS  p1_52_rwon  p1_52_rpt  p1_r_pct  p1_r_pct_JS  tourney_stats  \\\n",
       "0     0.343856       750.0     2182.0  0.343721     0.344525        0.66189   \n",
       "1     0.353614      1624.0     4348.0  0.373505     0.372607        0.66189   \n",
       "\n",
       "   best_of        score                                                pbp  \\\n",
       "0        3  6-7 6-3 6-4  SSSS;SSSS;SSSS;SSSS;SSSS;SRRSSS;RRSSRSSS;SSSS;...   \n",
       "1        3  6-7 6-3 6-3  SSSS;SSSS;SSSS;SSSS;SSSS;SSSS;SSSS;SSSS;SSRRSR...   \n",
       "\n",
       "   winner  \n",
       "0       1  \n",
       "1       1  \n",
       "\n",
       "[2 rows x 32 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can test this on our subset of 10,000 matches as well as all matches in the database:\n",
    "df = pd.read_csv('../my_data/elo_pbp_with_surface_8_22.csv')\n",
    "del df['Unnamed: 0']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elo baseline:  0.696569178853\n",
      "surface elo baseline:  0.691038620172\n",
      "best s_elo weight:  0.3 accuracy = 0.702099737533\n"
     ]
    }
   ],
   "source": [
    "print 'elo baseline: ',  sum((df['elo_diff']<0) == df['winner'])/float(len(df))\n",
    "print 'surface elo baseline: ', sum((df['s_elo_diff']<0) == df['winner'])/float(len(df))\n",
    "\n",
    "current = (0,0)\n",
    "for weight in np.arange(10)*.1:\n",
    "    accuracy = sum(((1-weight)*df['elo_diff']+weight*df['s_elo_diff']<0) == df['winner'])/float(len(df))\n",
    "    if accuracy > current[1]:\n",
    "        current=weight,accuracy\n",
    "print 'best s_elo weight: ',current[0],'accuracy =',current[1]\n",
    "df['elo_diff_weighted'] = (1-current[1])*df['elo_diff']+current[1]*df['s_elo_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% s_elo used in lm fit:  0.43309008408\n",
      "accuracy:  0.722475247525\n",
      "loss:  0.538804439863\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "\n",
    "kfold = KFold(n_splits=5,shuffle=True)\n",
    "scores = [],[]\n",
    "cols = ['elo_diff','s_elo_diff']\n",
    "for train_ind,test_ind in kfold.split(df):\n",
    "    lm = linear_model.LogisticRegression(fit_intercept = True)\n",
    "    train_df,test_df = df.loc[train_ind],df.loc[test_ind]\n",
    "    lm.fit(sub_df[cols].values.reshape([len(sub_df),len(cols)]),sub_df['winner'])\n",
    "    y_preds = lm.predict(test_df[cols].values.reshape([len(test_df),len(cols)]))\n",
    "    y_probs = lm.predict_proba(test_df[cols].values.reshape([len(test_df),len(cols)]))\n",
    "    accuracy = accuracy_score(test_df['winner'],y_preds)\n",
    "    loss = log_loss(test_df['winner'],y_probs,labels=[0,1])\n",
    "    scores[0].append(accuracy);scores[1].append(loss)\n",
    "print '% s_elo used in lm fit: ',lm.coef_[0][1]/(lm.coef_[0][0]+lm.coef_[0][1])\n",
    "print 'accuracy: ', np.mean(scores[0])\n",
    "print 'loss: ', np.mean(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00291231, -0.00222485]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# logistic regression on z scores of our probabilities AND elo_diff/s_elo_diff\n",
    "from scipy.stats import norm\n",
    "df_all = pd.read_csv('../my_data/feature_df_pbp3_8_23_alphas.csv')\n",
    "del df_all['Unnamed: 0']\n",
    "for col in ['sackmann_prob','klaassen_prob','klaassen_prob_a_400']:\n",
    "    df_all[col.replace('prob','z')] = norm.ppf(df_all[col])\n",
    "df_all.loc[df_all['sackmann_z']>10,'sackmann_z'] = 10\n",
    "df_all.loc[df_all['klaassen_z']>10,'klaassen_z'] = 10\n",
    "df_all.loc[df_all['klaassen_z_a_400']>10,'klaassen_z_a_400'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df_all['klaassen_z_a_400'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients:  [ -5.45725783e-04   1.73519587e-03   1.71256863e+00]\n",
      "accuracy:  0.77803661972\n",
      "loss:  0.456071683438\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "\n",
    "# also will want to try ensemble methods at some point...\n",
    "kfold = KFold(n_splits=5,shuffle=True)\n",
    "scores = [],[]\n",
    "cols = ['elo_diff','s_elo_diff','klaassen_z_a_400']\n",
    "for train_ind,test_ind in kfold.split(df_all):\n",
    "    lm = linear_model.LogisticRegression(fit_intercept = True)\n",
    "    train_df,test_df = df_all.loc[train_ind],df_all.loc[test_ind]\n",
    "    lm.fit(train_df[cols].values.reshape([len(train_df),len(cols)]),train_df['winner'])\n",
    "    y_preds = lm.predict(test_df[cols].values.reshape([len(test_df),len(cols)]))\n",
    "    y_probs = lm.predict_proba(test_df[cols].values.reshape([len(test_df),len(cols)]))\n",
    "    accuracy = accuracy_score(test_df['winner'],y_preds)\n",
    "    loss = log_loss(test_df['winner'],y_probs,labels=[0,1])\n",
    "    scores[0].append(accuracy);scores[1].append(loss)\n",
    "#print '% s_elo used in lm fit: ',lm.coef_[0][1]/(lm.coef_[0][0]+lm.coef_[0][1])\n",
    "print 'coefficients: ', lm.coef_[0]\n",
    "print 'accuracy: ', np.mean(scores[0])\n",
    "print 'loss: ', np.mean(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform same analysis across entire match dataset, over the decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-time fix to transfer over the elo_diff's\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# df_og = pd.read_csv('../my_data/elo_pbp_with_surface_8_22.csv')\n",
    "# del df_og['Unnamed: 0']\n",
    "# df = pd.read_csv('../my_data/feature_df_pbp3_8_23_alphas.csv')\n",
    "# del df['Unnamed: 0']\n",
    "\n",
    "# elo_dict = dict(zip(range(len(df_og)),df_og['elo_diff']))\n",
    "# s_elo_dict = dict(zip(range(len(df_og)),df_og['s_elo_diff']))\n",
    "\n",
    "# df['elo_diff'] = [elo_dict[m_id] for m_id in df['match_id']]\n",
    "# df['s_elo_diff'] = [s_elo_dict[m_id] for m_id in df['match_id']]\n",
    "# df.to_csv('../my_data/feature_df_pbp3_8_23_alphas.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
