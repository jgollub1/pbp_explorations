{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# determine the optimal pre-match forecast, given elo_diff and s_elo_diff\n",
    "# step 3: calculate glicko and s_glicko for each player and do the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_id</th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>tourney_date</th>\n",
       "      <th>match_year</th>\n",
       "      <th>p0_name</th>\n",
       "      <th>p1_name</th>\n",
       "      <th>p0_elo</th>\n",
       "      <th>p1_elo</th>\n",
       "      <th>elo_diff</th>\n",
       "      <th>p0_s_elo</th>\n",
       "      <th>...</th>\n",
       "      <th>tourney_stats</th>\n",
       "      <th>best_of</th>\n",
       "      <th>score</th>\n",
       "      <th>pbp</th>\n",
       "      <th>winner</th>\n",
       "      <th>match_id</th>\n",
       "      <th>p0_s_kls</th>\n",
       "      <th>p1_s_kls</th>\n",
       "      <th>p0_s_kls_JS</th>\n",
       "      <th>p1_s_kls_JS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-339</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2000</td>\n",
       "      <td>Thomas Enqvist</td>\n",
       "      <td>Arnaud Clement</td>\n",
       "      <td>1989.436848</td>\n",
       "      <td>1741.104988</td>\n",
       "      <td>248.33186</td>\n",
       "      <td>1939.223943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631615</td>\n",
       "      <td>3</td>\n",
       "      <td>6-3 6-4</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.590656</td>\n",
       "      <td>0.536052</td>\n",
       "      <td>0.592050</td>\n",
       "      <td>0.539075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-339</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2000</td>\n",
       "      <td>Jens Knippschild</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>1755.204529</td>\n",
       "      <td>1703.745759</td>\n",
       "      <td>51.45877</td>\n",
       "      <td>1597.559723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631615</td>\n",
       "      <td>3</td>\n",
       "      <td>6-1 6-4</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600610</td>\n",
       "      <td>0.577408</td>\n",
       "      <td>0.601691</td>\n",
       "      <td>0.580165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  tourney_id tourney_name tourney_date  match_year           p0_name  \\\n",
       "0   2000-339     Adelaide   2000-01-03        2000    Thomas Enqvist   \n",
       "1   2000-339     Adelaide   2000-01-03        2000  Jens Knippschild   \n",
       "\n",
       "          p1_name       p0_elo       p1_elo   elo_diff     p0_s_elo  \\\n",
       "0  Arnaud Clement  1989.436848  1741.104988  248.33186  1939.223943   \n",
       "1   Roger Federer  1755.204529  1703.745759   51.45877  1597.559723   \n",
       "\n",
       "      ...       tourney_stats  best_of    score   pbp  winner  match_id  \\\n",
       "0     ...            0.631615        3  6-3 6-4  None       1         0   \n",
       "1     ...            0.631615        3  6-1 6-4  None       0         1   \n",
       "\n",
       "   p0_s_kls  p1_s_kls  p0_s_kls_JS  p1_s_kls_JS  \n",
       "0  0.590656  0.536052     0.592050     0.539075  \n",
       "1  0.600610  0.577408     0.601691     0.580165  \n",
       "\n",
       "[2 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/Users/jacobgollub/Desktop/college (current)/research/pbp_explorations/scripts/sackmann')\n",
    "import tennisGameProbability,tennisMatchProbability,tennisSetProbability,tennisTiebreakProbability\n",
    "from tennisMatchProbability import matchProb\n",
    "from helper_functions import validate_results\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "\n",
    "# can test this on our subset of 10,000 matches as well as all matches in the database:\n",
    "#df = pd.read_csv('../my_data/elo_pbp_with_surface_8_27.csv')\n",
    "df = pd.read_csv('../my_data/elo_atp_matches_21st_century_9_2.csv')\n",
    "del df['Unnamed: 0']\n",
    "\n",
    "# currently looking at 2014 tour-level matches, excluding Davis Cup\n",
    "#df = df[df['match_year']==2014].reset_index(drop=True)\n",
    "#df = df[df['match_year'].isin([2013,2014,2015,2016])]\n",
    "df = df[df['tourney_name']!='Davis Cup'].reset_index(drop=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.loc[39289]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46222, 48)\n"
     ]
    }
   ],
   "source": [
    "# generate match probabilities and z-scores for Klaassen method, with and w/o JS estimators\n",
    "df['match_prob_kls'] = [matchProb(row['p0_s_kls'],1-row['p1_s_kls']) for i,row in df.iterrows()]\n",
    "df['match_prob_kls_JS'] = [matchProb(row['p0_s_kls_JS'],1-row['p1_s_kls_JS']) for i,row in df.iterrows()]\n",
    "\n",
    "from scipy.stats import norm\n",
    "for col in ['match_prob_kls','match_prob_kls_JS']:\n",
    "    df[col.replace('prob','z')] = norm.ppf(df[col])\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elo 538 baseline:  0.677664315694\n",
      "0.618563286636\n",
      "0.612628547157\n",
      "surface elo 538 baseline:  0.67850806975\n",
      "best s_elo weight:  0.5 accuracy = 0.684133096794\n"
     ]
    }
   ],
   "source": [
    "print 'elo 538 baseline: ',  sum((df['elo_diff_538']>0) == df['winner'])/float(len(df))\n",
    "print log_loss(df['winner'],[(1+10**(diff/-400.))**-1 for diff in df['elo_diff_538']])\n",
    "print log_loss(df['winner'],[(1+10**(diff/-400.))**-1 for diff in df['s_elo_diff_538']])\n",
    "\n",
    "\n",
    "print 'surface elo 538 baseline: ', sum((df['s_elo_diff_538']>0) == df['winner'])/float(len(df))\n",
    "\n",
    "current = (0,0)\n",
    "for weight in np.arange(11)*.1:\n",
    "    accuracy = sum(((1-weight)*df['elo_diff_538']+weight*df['s_elo_diff_538']>0) == df['winner'])/float(len(df))\n",
    "    if accuracy > current[1]:\n",
    "        current=weight,accuracy\n",
    "print 'best s_elo weight: ',current[0],'accuracy =',current[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elo baseline:  0.689199920588\n",
      "surface elo baseline:  0.683541790748\n",
      "best s_elo weight:  0.3 accuracy = 0.694361723248\n"
     ]
    }
   ],
   "source": [
    "# print 'elo baseline: ',  sum((df['elo_diff']>0) == df['winner'])/float(len(df))\n",
    "# print 'surface elo baseline: ', sum((df['s_elo_diff']>0) == df['winner'])/float(len(df))\n",
    "\n",
    "# current = (0,0)\n",
    "# for weight in np.arange(10)*.1:\n",
    "#     accuracy = sum(((1-weight)*df['elo_diff']+weight*df['s_elo_diff']>0) == df['winner'])/float(len(df))\n",
    "#     if accuracy > current[1]:\n",
    "#         current=weight,accuracy\n",
    "# print 'best s_elo weight: ',current[0],'accuracy =',current[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seems worth trying methods to alter match_prob_kls with elo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b303f9f08c9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'elo_diff_538'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'elo_diff'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m's_elo_diff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'elo_diff_538'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m's_elo_diff_538'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;34m[\u001b[0m\u001b[0;34m'elo_diff'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m's_elo_diff'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'match_z_kls'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;34m[\u001b[0m\u001b[0;34m'elo_diff_538'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m's_elo_diff_538'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'match_z_kls'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvalidate_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jacobgollub/anaconda/lib/python2.7/site-packages/helper_functions.pyc\u001b[0m in \u001b[0;36mvalidate_results\u001b[0;34m(df, columns, n_splits)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcols\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'winner'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0my_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jacobgollub/anaconda/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64,\n\u001b[0;32m-> 1173\u001b[0;31m                          order=\"C\")\n\u001b[0m\u001b[1;32m   1174\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jacobgollub/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/jacobgollub/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jacobgollub/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "cols = [['elo_diff_538'],['elo_diff','s_elo_diff'],['elo_diff_538','s_elo_diff_538'],\\\n",
    "        ['elo_diff','s_elo_diff','match_z_kls'],\\\n",
    "        ['elo_diff_538','s_elo_diff_538','match_z_kls']]\n",
    "n_splits = 5\n",
    "validate_results(df,cols,n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now, create win_prob columns for elo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# logistic regression on z scores of our probabilities AND elo_diff/s_elo_diff\n",
    "from scipy.stats import norm\n",
    "df_all = pd.read_csv('../my_data/feature_df_pbp3_8_23_alphas.csv')\n",
    "del df_all['Unnamed: 0']\n",
    "for col in ['sackmann_prob','klaassen_prob','klaassen_prob_a_400']:\n",
    "    df_all[col.replace('prob','z')] = norm.ppf(df_all[col])\n",
    "df_all.loc[df_all['sackmann_z']>10,'sackmann_z'] = 10\n",
    "df_all.loc[df_all['klaassen_z']>10,'klaassen_z'] = 10\n",
    "df_all.loc[df_all['klaassen_z_a_400']>10,'klaassen_z_a_400'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients:  [ -5.39480879e-04   1.72440109e-03   1.71413858e+00]\n",
      "accuracy:  0.778048803942\n",
      "loss:  0.456072287662\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "\n",
    "# also will want to try ensemble methods at some point...\n",
    "kfold = KFold(n_splits=5,shuffle=True)\n",
    "scores = [],[]\n",
    "cols = ['elo_diff','s_elo_diff','klaassen_z_a_400']\n",
    "for train_ind,test_ind in kfold.split(df_all):\n",
    "    lm = linear_model.LogisticRegression(fit_intercept = True)\n",
    "    train_df,test_df = df_all.loc[train_ind],df_all.loc[test_ind]\n",
    "    lm.fit(train_df[cols].values.reshape([len(train_df),len(cols)]),train_df['winner'])\n",
    "    y_preds = lm.predict(test_df[cols].values.reshape([len(test_df),len(cols)]))\n",
    "    y_probs = lm.predict_proba(test_df[cols].values.reshape([len(test_df),len(cols)]))\n",
    "    accuracy = accuracy_score(test_df['winner'],y_preds)\n",
    "    loss = log_loss(test_df['winner'],y_probs,labels=[0,1])\n",
    "    scores[0].append(accuracy);scores[1].append(loss)\n",
    "#print '% s_elo used in lm fit: ',lm.coef_[0][1]/(lm.coef_[0][0]+lm.coef_[0][1])\n",
    "print 'coefficients: ', lm.coef_[0]\n",
    "print 'accuracy: ', np.mean(scores[0])\n",
    "print 'loss: ', np.mean(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform same analysis across entire match dataset, over the decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-time fix to transfer over the elo_diff's\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# df_og = pd.read_csv('../my_data/elo_pbp_with_surface_8_22.csv')\n",
    "# del df_og['Unnamed: 0']\n",
    "# df = pd.read_csv('../my_data/feature_df_pbp3_8_23_alphas.csv')\n",
    "# del df['Unnamed: 0']\n",
    "\n",
    "# elo_dict = dict(zip(range(len(df_og)),df_og['elo_diff']))\n",
    "# s_elo_dict = dict(zip(range(len(df_og)),df_og['s_elo_diff']))\n",
    "\n",
    "# df['elo_diff'] = [elo_dict[m_id] for m_id in df['match_id']]\n",
    "# df['s_elo_diff'] = [s_elo_dict[m_id] for m_id in df['match_id']]\n",
    "# df.to_csv('../my_data/feature_df_pbp3_8_23_alphas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import linear_model\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import log_loss,accuracy_score\n",
    "\n",
    "# n_splits = 5\n",
    "# kfold = KFold(n_splits=n_splits,shuffle=True)\n",
    "# scores = np.zeros([3,2,n_splits]);i=0\n",
    "# cols = ['elo_diff','s_elo_diff']\n",
    "# for train_ind,test_ind in kfold.split(df):\n",
    "#     lm = linear_model.LogisticRegression(fit_intercept = True)\n",
    "#     train_df,test_df = df.loc[train_ind],df.loc[test_ind]\n",
    "#     lm.fit(train_df[cols].values.reshape([len(train_df),len(cols)]),train_df['winner'])\n",
    "#     y_preds = lm.predict(test_df[cols].values.reshape([len(test_df),len(cols)]))\n",
    "#     y_preds2 = test_df['match_prob_kls']>.5\n",
    "#     y_preds3 = test_df['match_prob_kls_JS']>.5\n",
    "#     y_probs = lm.predict_proba(test_df[cols].values.reshape([len(test_df),len(cols)]))\n",
    "#     scores[0][0][i]=accuracy_score(test_df['winner'],y_preds)\n",
    "#     scores[0][1][i]=log_loss(test_df['winner'],y_probs,labels=[0,1])\n",
    "#     scores[1][0][i]=accuracy_score(test_df['winner'],y_preds2)\n",
    "#     scores[1][1][i]=log_loss(test_df['winner'],test_df['match_prob_kls'],labels=[0,1])\n",
    "#     scores[2][0][i]=accuracy_score(test_df['winner'],y_preds3)\n",
    "#     scores[2][1][i]=log_loss(test_df['winner'],test_df['match_prob_kls_JS'],labels=[0,1])\n",
    "\n",
    "    \n",
    "#     i+=1\n",
    "# print '% s_elo used in lm fit: ',lm.coef_[0][1]/(lm.coef_[0][0]+lm.coef_[0][1])\n",
    "# print 'accuracy: ', np.mean(scores[0][0])\n",
    "# print 'loss: ', np.mean(scores[0][1])\n",
    "\n",
    "# print 'kls probabilities'\n",
    "# print 'accuracy: ', np.mean(scores[1][0])\n",
    "# print 'loss: ', np.mean(scores[1][1])\n",
    "\n",
    "# print 'kls JS probabilities'\n",
    "# print 'accuracy: ', np.mean(scores[2][0])\n",
    "# print 'loss: ', np.mean(scores[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import linear_model\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import log_loss,accuracy_score\n",
    "\n",
    "# # cols is a list of all column sets to test; compare with kls pre-match forecasts\n",
    "# def validate_results(df,columns,n_splits=5):\n",
    "#     kfold = KFold(n_splits=n_splits,shuffle=True)\n",
    "#     scores = np.zeros([len(columns)+2,2,n_splits]);i=0\n",
    "#     for train_ind,test_ind in kfold.split(df):\n",
    "#         lm = linear_model.LogisticRegression(fit_intercept = True)\n",
    "#         train_df,test_df = df.loc[train_ind],df.loc[test_ind]\n",
    "        \n",
    "#         for k,cols in enumerate(columns):\n",
    "#             lm.fit(train_df[cols].values.reshape([len(train_df),len(cols)]),train_df['winner'])\n",
    "#             y_preds = lm.predict(test_df[cols].values.reshape([len(test_df),len(cols)]))\n",
    "#             y_probs = lm.predict_proba(test_df[cols].values.reshape([len(test_df),len(cols)]))\n",
    "#             scores[k][0][i]=accuracy_score(test_df['winner'],y_preds)\n",
    "#             scores[k][1][i]=log_loss(test_df['winner'],y_probs,labels=[0,1])\n",
    "        \n",
    "#         y_preds2 = test_df['match_prob_kls']>.5\n",
    "#         y_preds3 = test_df['match_prob_kls_JS']>.5\n",
    "#         scores[len(columns)][0][i]=accuracy_score(test_df['winner'],y_preds2)\n",
    "#         scores[len(columns)][1][i]=log_loss(test_df['winner'],test_df['match_prob_kls'],labels=[0,1])\n",
    "#         scores[len(columns)+1][0][i]=accuracy_score(test_df['winner'],y_preds3)\n",
    "#         scores[len(columns)+1][1][i]=log_loss(test_df['winner'],test_df['match_prob_kls_JS'],labels=[0,1])\n",
    "#         i+=1\n",
    "    \n",
    "#     for i,cols in enumerate(columns):\n",
    "#         print 'columns: ',cols\n",
    "#         #print '% s_elo used in lm fit: ',lm.coef_[0][1]/(lm.coef_[0][0]+lm.coef_[0][1])\n",
    "#         print 'accuracy: ', np.mean(scores[i][0])\n",
    "#         print 'loss: ', np.mean(scores[i][1])\n",
    "    \n",
    "#     print 'kls probabilities'\n",
    "#     print 'accuracy: ', np.mean(scores[len(columns)][0])\n",
    "#     print 'loss: ', np.mean(scores[len(columns)][1])\n",
    "\n",
    "#     print 'kls JS probabilities'\n",
    "#     print 'accuracy: ', np.mean(scores[len(columns)+1][0])\n",
    "#     print 'loss: ', np.mean(scores[len(columns)+1][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
