{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tny_id</th>\n",
       "      <th>tny_name</th>\n",
       "      <th>surface</th>\n",
       "      <th>tny_date</th>\n",
       "      <th>match_year</th>\n",
       "      <th>match_month</th>\n",
       "      <th>p0_name</th>\n",
       "      <th>p1_name</th>\n",
       "      <th>p0_elo</th>\n",
       "      <th>p1_elo</th>\n",
       "      <th>...</th>\n",
       "      <th>match_prob_sf_kls_JS</th>\n",
       "      <th>match_prob_adj_kls</th>\n",
       "      <th>match_prob_adj_kls_JS</th>\n",
       "      <th>elo_prob</th>\n",
       "      <th>elo_prob_538</th>\n",
       "      <th>sf_elo_prob</th>\n",
       "      <th>sf_elo_prob_538</th>\n",
       "      <th>s_total</th>\n",
       "      <th>p0_s_kls_elo</th>\n",
       "      <th>p1_s_kls_elo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-375</td>\n",
       "      <td>Montpellier</td>\n",
       "      <td>Hard</td>\n",
       "      <td>2010-10-25</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>Romain Jouan</td>\n",
       "      <td>Taylor Dent</td>\n",
       "      <td>1514.919312</td>\n",
       "      <td>1659.920646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580319</td>\n",
       "      <td>0.213863</td>\n",
       "      <td>0.211482</td>\n",
       "      <td>0.302653</td>\n",
       "      <td>0.209638</td>\n",
       "      <td>0.337195</td>\n",
       "      <td>0.269816</td>\n",
       "      <td>1.346929</td>\n",
       "      <td>0.652090</td>\n",
       "      <td>0.694839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-375</td>\n",
       "      <td>Montpellier</td>\n",
       "      <td>Hard</td>\n",
       "      <td>2010-10-25</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>Julian Reister</td>\n",
       "      <td>Richard Gasquet</td>\n",
       "      <td>1557.421050</td>\n",
       "      <td>1886.196622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243984</td>\n",
       "      <td>0.282590</td>\n",
       "      <td>0.285650</td>\n",
       "      <td>0.130950</td>\n",
       "      <td>0.147258</td>\n",
       "      <td>0.130129</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>1.353852</td>\n",
       "      <td>0.629991</td>\n",
       "      <td>0.723861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tny_id     tny_name surface    tny_date  match_year  match_month  \\\n",
       "0  2010-375  Montpellier    Hard  2010-10-25        2010           10   \n",
       "1  2010-375  Montpellier    Hard  2010-10-25        2010           10   \n",
       "\n",
       "          p0_name          p1_name       p0_elo       p1_elo      ...       \\\n",
       "0    Romain Jouan      Taylor Dent  1514.919312  1659.920646      ...        \n",
       "1  Julian Reister  Richard Gasquet  1557.421050  1886.196622      ...        \n",
       "\n",
       "   match_prob_sf_kls_JS  match_prob_adj_kls  match_prob_adj_kls_JS  elo_prob  \\\n",
       "0              0.580319            0.213863               0.211482  0.302653   \n",
       "1              0.243984            0.282590               0.285650  0.130950   \n",
       "\n",
       "   elo_prob_538  sf_elo_prob  sf_elo_prob_538   s_total  p0_s_kls_elo  \\\n",
       "0      0.209638     0.337195         0.269816  1.346929      0.652090   \n",
       "1      0.147258     0.130129         0.043000  1.353852      0.629991   \n",
       "\n",
       "   p1_s_kls_elo  \n",
       "0      0.694839  \n",
       "1      0.723861  \n",
       "\n",
       "[2 rows x 95 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper_functions import validate_results\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "\n",
    "# can test this on our subset of 10,000 matches as well as all matches in the database:\n",
    "df = pd.read_csv('../my_data/elo_pbp_with_surface_10_2.csv')\n",
    "del df['Unnamed: 0']\n",
    "\n",
    "# currently looking at 2014 tour-level matches, excluding Davis Cup\n",
    "df = df[df['match_year'].isin([2010,2011,2012,2013,2014])].reset_index(drop=True)\n",
    "df = df[df['tny_name']!='Davis Cup'].reset_index(drop=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match_d = dict(zip(list(set(df['match_id'])),[1]*len(df)))\n",
    "train_d = dict(zip(list(set(df[df['match_year']<=2013]['match_id'])),[1]*len(df)))\n",
    "test_d = dict(zip(list(set(df[df['match_year']==2014]['match_id'])),[1]*len(df)))\n",
    "col_d = {'Clay':0,'Hard':1,'Grass':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../my_data/feature_df_pbp3_10_2.csv')\n",
    "df2 = df2.loc[np.array([m_id in match_d for m_id in df2['match_id']])]\n",
    "df2['current_set'] = df2['sets_0'] + df2['sets_1'] + 1\n",
    "df2['final_set'] = df2['current_set']==3\n",
    "df2['surface_num'] = [col_d[surface] for surface in df2['surface']]\n",
    "df2['set_diff'] = df2['sets_0'] - df2['sets_1']\n",
    "df2['point_diff'] = df2['points_0'] - df2['points_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['match_id','final_set','surface_num','elo_diff','set_diff','break_adv','point_diff','winner']\n",
    "\n",
    "train_df = df2.loc[np.array([m_id in train_d for m_id in df2['match_id']])][cols]\n",
    "test_df = df2.loc[np.array([m_id in test_d for m_id in df2['match_id']])][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_features': [2, 3, 6], 'min_samples_split': [100, 500, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from helper_functions import *\n",
    "# try with smaller df first\n",
    "val_df = train_df\n",
    "\n",
    "hyper_params = {'max_features':[2,3,6],'min_samples_split':[100,500,1000]}\n",
    "clf = GridSearchCV(RandomForestClassifier(),hyper_params,scoring='neg_log_loss',cv=5)\n",
    "clf.fit(val_df[cols[:-1]],val_df[cols[-1]])\n",
    "\n",
    "#cross_validate(val_df,clf,cols=cols[:-1],target=cols[-1:],hyper_parameters=hyper_params,n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 3, 'min_samples_split': 1000}\n"
     ]
    }
   ],
   "source": [
    "best_idx = np.argmin(clf.cv_results_['rank_test_score'])\n",
    "best = clf.cv_results_['params'][best_idx]\n",
    "print best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.00743419, -0.62372245, -0.61753299, -1.20548113, -0.70073222,\n",
       "       -0.60705003, -2.11536779, -0.95272265, -0.74734569])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for m in m_features:\n",
    "#     for t_node in t_node_sizes:\n",
    "#         RF = RandomForestRegressor(n_estimators=300,max_features=m,min_samples_split=t_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now, train a random forest model on 2010-2013 match data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate(val_df,clf,cols,target,hyper_parameters,n_splits):\n",
    "    print 'searching for hyperparams...'\n",
    "    ids = list(set(val_df['match_id']))\n",
    "    vfunc = np.vectorize(in_dict)\n",
    "    kfold = KFold(n_splits=n_splits,shuffle=True)\n",
    "    key = hyper_parameters.keys()[0]\n",
    "    scores = np.array()\n",
    "    \n",
    "    for train_index,____ in kfold.split(ids):\n",
    "        train_dict = dict(zip(train_index,[1]*len(train_index)))\n",
    "        train_ind = vfunc(np.array(val_df['match_id']),train_dict)\n",
    "        test_ind = (1 - train_ind)==1\n",
    "        Xtrain, ytrain = val_df[cols][train_ind], np.array(val_df[target][train_ind]).reshape([(sum(train_ind),)])\n",
    "        Xtest, ytest = val_df[cols][test_ind], np.array(val_df[target][test_ind]).reshape([(sum(test_ind),)])\n",
    "        \n",
    "        # retrieve classification score for every hyper_parameter fed into this function\n",
    "        # LOOP THROUGH ALL KEYS here if you want to test multiple hyper_params\n",
    "        for j in xrange(len(hyper_parameters[key])):\n",
    "            setattr(clf,key,hyper_parameters[key][j])\n",
    "            clf.fit(Xtrain,ytrain)\n",
    "            score = clf.score(Xtest,ytest)\n",
    "            scores[j].append(score)\n",
    "    for i in range(len(scores)):\n",
    "        print hyper_parameters[key][i],': ',np.mean(scores[i])\n",
    "    best_ind = np.argmax([np.mean(a) for a in scores])\n",
    "    print 'best: ',{key:hyper_parameters[key][best_ind]}\n",
    "    return {key:hyper_parameters[key][best_ind]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
